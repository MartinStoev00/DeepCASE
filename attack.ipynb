{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-12T11:27:30.677266Z",
     "start_time": "2024-09-12T11:27:25.629823Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchattacks\n",
    "from deepcase_copy.context_builder import ContextBuilder\n",
    "from deepcase_copy.preprocessing import Preprocessor\n",
    "\n",
    "builder = ContextBuilder.load('save/builder.save')\n",
    "preprocessor = Preprocessor(\n",
    "    length=10,  # 10 events in context\n",
    "    timeout=86400,  # Ignore events older than 1 day (60*60*24 = 86400 seconds)\n",
    ")\n",
    "context, events, labels, mapping = preprocessor.csv('alerts.csv', verbose=True)\n",
    "\n",
    "# In case no labels are provided, set labels to -1\n",
    "# IMPORTANT: If no labels are provided, make sure to manually set the labels\n",
    "# before calling the interpreter.score_clusters method. Otherwise, this will\n",
    "# raise an exception, because scores == NO_SCORE cannot be computed.\n",
    "if labels is None:\n",
    "    labels = np.full(events.shape[0], -1, dtype=int)\n",
    "\n",
    "# Cast to cuda if available\n",
    "if torch.cuda.is_available():\n",
    "    builder = builder.to('cuda')\n",
    "    events = events.to('cuda')\n",
    "    context = context.to('cuda')\n",
    "\n",
    "\n",
    "# Split into train and test sets (20:80) by time - assuming events are ordered chronologically\n",
    "events_train  = events [:events.shape[0]//5 ]\n",
    "events_test   = events [ events.shape[0]//5:]\n",
    "\n",
    "context_train = context[:events.shape[0]//5 ]\n",
    "context_test  = context[ events.shape[0]//5:]\n",
    "\n",
    "labels_train  = labels [:events.shape[0]//5 ]\n",
    "labels_test   = labels [ events.shape[0]//5:]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 3353/3353 [00:00<00:00, 3442.40it/s]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T11:27:32.008730Z",
     "start_time": "2024-09-12T11:27:32.004945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l = 1\n",
    "\n",
    "chosen_index = 0\n",
    "context_picked = context[chosen_index:chosen_index+l]\n",
    "events_picked = events[chosen_index:chosen_index+l]\n",
    "labels_picked = labels[chosen_index:chosen_index+l]\n",
    "# confidence, attention = builder.predict(context_picked)\n",
    "# topk = torch.topk(confidence[0][0], 1)\n",
    "# context_picked, events_picked, attention[0][0], topk\n",
    "# for i in range(l):\n",
    "#     if labels_picked[i] not in [1,2,3]:\n",
    "#         print(labels_picked[i], context_picked[i], events_picked[i])"
   ],
   "id": "17dde4680652c812",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T11:31:11.584659Z",
     "start_time": "2024-09-12T11:31:11.579167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# cim = builder.embedding_one_hot(context_picked)\n",
    "# cim.requires_grad_(True)\n",
    "# output = builder.predict(cim)"
   ],
   "id": "68c601bbfed77a4f",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-12T11:43:14.469598Z",
     "start_time": "2024-09-12T11:43:14.445547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deepcase_copy.context_builder.loss import LabelSmoothing\n",
    "\n",
    "def max_to_one(tensor):\n",
    "    max_indices = torch.argmax(tensor, dim=-1, keepdim=True)\n",
    "    result = torch.zeros_like(tensor)\n",
    "    result.scatter_(-1, max_indices, 1.0)\n",
    "    return result\n",
    "\n",
    "def print_results(results, i):\n",
    "    results_picked = torch.topk(results[0][0][0], 3)\n",
    "    exp = results_picked.values.exp()\n",
    "    indices = results_picked.indices\n",
    "    s = \"\"\n",
    "    for j in range(3):\n",
    "        s += f\"[{indices[j].item()}] {round(exp[j].item(), 3)}, \"\n",
    "    print(f\"Prediction {i}: {s}\")\n",
    "    return indices\n",
    "\n",
    "def compute_change(trace, original, epsilon=0.1):\n",
    "    a = torch.clamp(original - epsilon, min=0)\n",
    "    b = (trace >= a).float() * trace + (trace < a).float() * a\n",
    "    c = (b > original + epsilon).float() * (original + epsilon) + (b <= original + epsilon).float() * b\n",
    "    return torch.clamp(c, max=1).detach()\n",
    "\n",
    "def bim_attack(context_given, target_given, alpha=0.1, epsilon=0.1, num_iterations=10):\n",
    "    change = None\n",
    "    original_context = builder.embedding_one_hot(context_given)\n",
    "    context_processed = builder.embedding_one_hot(context_given)\n",
    "    criterion = LabelSmoothing(builder.decoder_event.out.out_features, 0.1)    \n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        context_processed.requires_grad_(True)\n",
    "        output = builder.predict(context_processed)\n",
    "        indices = print_results(output, i)\n",
    "        if events_picked[0] not in indices:\n",
    "            break\n",
    "        loss = criterion(output[0][0], events_picked)\n",
    "        loss.backward()\n",
    "        grad = context_processed.grad.sign()\n",
    "        if change is None:\n",
    "            change = alpha * grad\n",
    "        else:\n",
    "            change += alpha * grad\n",
    "        context_processed = context_processed + change\n",
    "        context_processed = compute_change(context_processed, original_context, epsilon)\n",
    "        \n",
    "bim_attack(context_given=context_picked, target_given=events_picked, alpha=0.1, epsilon=0.1, num_iterations=10)"
   ],
   "id": "aed0a48282625435",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 0: [64] 0.341, [72] 0.282, [24] 0.143, \n",
      "Prediction 1: [64] 0.724, [24] 0.125, [57] 0.04, \n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-06T11:25:08.619709Z",
     "start_time": "2024-09-06T11:25:08.611118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# class SimpleModel(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(SimpleModel, self).__init__()\n",
    "#         self.fc = nn.Linear(input_size, output_size)\n",
    "#     \n",
    "#     def forward(self, x):\n",
    "#         return self.fc(x)\n",
    "# \n",
    "# input_size = 270 \n",
    "# output_size = 1\n",
    "# model = SimpleModel(input_size, output_size)\n",
    "# int_input = torch.tensor([[2, 3, 5]], dtype=torch.int64)  # Integer-valued input\n",
    "# \n",
    "# def one_hot_encode(int_tensor, num_classes):\n",
    "#     return torch.nn.functional.one_hot(int_tensor, num_classes).float()\n",
    "# \n",
    "# one_hot_input = one_hot_encode(int_input, 90).view(1, -1)  \n",
    "# one_hot_input.requires_grad_(True)\n",
    "# target = torch.tensor([[10.0]], dtype=torch.float32)\n",
    "# criterion = nn.MSELoss()\n",
    "# output = model(one_hot_input)\n",
    "# loss = criterion(output, target)\n",
    "# loss.backward()\n",
    "# print(output, target)\n",
    "# print(one_hot_input.grad)\n"
   ],
   "id": "81432f72cfa4713d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1143]], grad_fn=<AddmmBackward0>) tensor([[10.]])\n",
      "tensor([[-0.1077, -0.1853,  1.0463, -0.4446,  0.1205, -0.6067, -0.1476,  0.3568,\n",
      "         -0.1219,  1.1074,  0.1277, -0.7452, -0.7724, -0.6487, -0.0372,  1.0985,\n",
      "          0.7424,  0.3551,  0.9772, -0.5586,  1.2131,  1.0179, -1.1229, -0.3037,\n",
      "          0.8177,  0.8633,  1.0296, -0.6272, -0.4376, -0.7597,  0.0471, -0.4535,\n",
      "          1.0059, -1.1586,  0.1231,  0.8764, -0.3022, -0.3063, -0.6398,  1.0514,\n",
      "         -1.2093,  1.0124, -0.9577, -0.1990,  0.5465,  0.1698, -0.8128,  0.5603,\n",
      "          0.9736,  0.6556,  0.0100, -0.7559,  0.6390,  0.2965, -0.6951, -0.7969,\n",
      "         -0.7412, -0.0679, -0.8584,  0.4403, -0.4508,  0.9497,  0.6262, -0.8821,\n",
      "          0.5530, -0.0623, -0.0568,  0.7504,  0.1850,  0.3488, -0.0998,  0.3175,\n",
      "          0.0525,  0.4194,  1.1491,  0.1296,  1.1290,  1.0317,  0.2275,  0.8821,\n",
      "          0.2675, -0.4814, -0.4393, -1.1878,  0.5852,  0.5016,  0.2002,  0.5551,\n",
      "         -0.9502, -0.6856, -0.1387, -0.9701, -0.8539,  1.2102, -0.8799,  0.7915,\n",
      "         -0.3754,  1.1583, -0.5349, -0.1986, -0.5564, -0.4042, -0.3005,  0.7678,\n",
      "          0.3360,  0.8389, -1.1607,  0.8804, -0.4085,  0.0204,  0.9844, -0.9673,\n",
      "          0.4315, -0.1739, -0.3573,  0.2438, -1.1486, -1.1989, -0.3739, -0.2793,\n",
      "         -0.2635,  0.1489, -0.1224,  0.8150,  0.7912,  0.5151,  0.9811, -1.0274,\n",
      "         -0.2887, -0.6174, -0.1988, -0.6045, -0.4069, -0.7492, -0.8124, -0.8218,\n",
      "         -0.5503, -0.1969,  0.3645,  1.0798,  0.4783,  0.0040,  0.8554, -0.0659,\n",
      "         -0.2893, -1.1524,  0.4908,  0.3663, -0.9625,  0.5071,  0.0152, -0.8825,\n",
      "         -0.9170,  0.6196,  0.3394, -0.4265, -0.1627, -0.8447,  0.4620, -1.1359,\n",
      "          0.6538, -0.1810,  1.0314, -0.4555, -1.2173,  0.0251,  0.9670,  0.4549,\n",
      "          0.8131, -0.1542, -0.0814,  0.1095, -0.4056,  0.6528, -1.2021,  0.1059,\n",
      "          0.7326,  0.6804, -0.2708, -0.7632, -0.3859,  1.1581,  0.3682, -0.8408,\n",
      "         -0.3962, -0.9524, -0.6621, -0.9177, -0.8428, -0.9996,  0.9434, -0.7719,\n",
      "         -0.4038,  0.1379,  0.6495,  0.9916, -0.9449,  0.5798,  0.6420,  0.4509,\n",
      "          1.1258, -1.0832, -0.6856, -0.8273,  0.3528,  0.1560,  0.2222,  0.8626,\n",
      "          0.3843,  1.1261,  0.1237,  0.0367, -0.1983, -0.1293,  0.8209,  0.1938,\n",
      "         -0.0286, -0.1136,  0.2980, -1.1308,  1.2293,  1.1966,  0.3708,  0.4839,\n",
      "          0.9452,  1.1826,  0.2361, -0.8832,  0.3478,  0.3891,  0.3940, -0.5125,\n",
      "         -0.9317, -1.1768, -1.1997,  1.0571, -0.4374,  0.7002,  0.9905,  0.9955,\n",
      "         -1.1953,  0.6878, -0.7818, -0.9004, -1.0977, -1.0308,  0.4889,  0.1409,\n",
      "         -1.1886,  0.1171, -0.0436,  0.2705,  0.1505,  1.0102,  1.0267, -0.4022,\n",
      "          0.0831, -0.6996, -0.4299,  0.2618, -0.1899,  0.6619, -0.4242,  0.3209,\n",
      "          0.5501, -0.9806, -0.6160, -1.1563,  1.0188, -0.7701]])\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
