{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:30.194281Z",
     "start_time": "2024-09-23T13:55:30.155735Z"
    }
   },
   "source": [
    "import torch\n",
    "from deepcase_copy.context_builder.context_builder import ContextBuilder\n",
    "from deepcase_copy.interpreter.interpreter import Interpreter\n",
    "\n",
    "def to_cuda(item):\n",
    "    if torch.cuda.is_available():\n",
    "        return item.to('cuda')\n",
    "    return item\n",
    "\n",
    "builder = to_cuda(ContextBuilder.load('save/builder.save'))\n",
    "interpreter = Interpreter.load('save/interpreter.save', builder)\n",
    "\n",
    "with open('save/sequences.save', 'rb') as infile:\n",
    "    data = torch.load(infile)\n",
    "    events  = data[\"events\"]\n",
    "    context = data[\"context\"]\n",
    "    labels  = data[\"labels\"]\n",
    "    mapping = data[\"mapping\"]\n",
    "    \n",
    "    events_train  = to_cuda(events [:events.shape[0]//5 ])\n",
    "    events_test   = to_cuda(events [ events.shape[0]//5:])\n",
    "    \n",
    "    context_train = to_cuda(context[:events.shape[0]//5 ])\n",
    "    context_test  = to_cuda(context[ events.shape[0]//5:])\n",
    "    \n",
    "    labels_train  = to_cuda(labels [:events.shape[0]//5 ])\n",
    "    labels_test   = to_cuda(labels [ events.shape[0]//5:])"
   ],
   "outputs": [],
   "execution_count": 337
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:33.189820Z",
     "start_time": "2024-09-23T13:55:30.195790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_unique_indices_per_row(tensor):\n",
    "    indices_list = []\n",
    "    row_list = []\n",
    "    indices_list_set = set()\n",
    "    \n",
    "    for row in range(len(tensor)):\n",
    "        curr = tuple(tensor[row].tolist())\n",
    "        \n",
    "        if curr in indices_list_set:\n",
    "            continue\n",
    "        \n",
    "        row_list.append(curr)\n",
    "        indices_list.append(row)\n",
    "        indices_list_set.add(curr)\n",
    "    \n",
    "    return indices_list, row_list\n",
    "indices, rows = get_unique_indices_per_row(context_test)"
   ],
   "id": "fc89a960fc4f0603",
   "outputs": [],
   "execution_count": 338
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:33.204403Z",
     "start_time": "2024-09-23T13:55:33.191085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deepcase_copy.context_builder.loss import LabelSmoothing\n",
    "\n",
    "MAX_ITER = 100\n",
    "\n",
    "def max_to_one(tensor):\n",
    "    max_indices = torch.argmax(tensor, dim=-1, keepdim=True)\n",
    "    result = torch.zeros_like(tensor)\n",
    "    result.scatter_(-1, max_indices, 1.0)\n",
    "    return result\n",
    "\n",
    "def get_results(results):\n",
    "    results_picked = torch.topk(results[0][0][0], 3)\n",
    "    exp = results_picked.values.exp()\n",
    "    res_indices = results_picked.indices\n",
    "    s = []\n",
    "    for j in range(3):\n",
    "        s.append(f\"{format_list([res_indices[j].item()])} {'{:.3f}'.format(exp[j])}\")\n",
    "    return res_indices, \", \".join(s)\n",
    "\n",
    "def compute_change(trace, original, epsilon=0.1):\n",
    "    a = torch.clamp(original - epsilon, min=0)\n",
    "    b = (trace >= a).float() * trace + (trace < a).float() * a\n",
    "    c = (b > original + epsilon).float() * (original + epsilon) + (b <= original + epsilon).float() * b\n",
    "    return max_to_one(c)\n",
    "\n",
    "def bim_attack(context_given, target_given, alpha=0.1, epsilon=0.1, num_iterations=MAX_ITER):\n",
    "    change = None\n",
    "    original_context = to_one_hot(context_given)\n",
    "    context_processed = to_one_hot(context_given)\n",
    "    criterion = LabelSmoothing(builder.decoder_event.out.out_features, 0.1)    \n",
    "    changes = []\n",
    "    for i in range(num_iterations):\n",
    "        context_processed.requires_grad_(True)\n",
    "        output = builder.predict(context_processed)\n",
    "        indices_of_results, prediction_str = get_results(output)\n",
    "        changes.append({\n",
    "            \"changed_to\": torch.argmax(context_processed, axis=-1).tolist()[0],\n",
    "            \"prediction_str\": prediction_str,\n",
    "        })\n",
    "        if target_given[0] != indices_of_results[0]:\n",
    "            break\n",
    "        loss = criterion(output[0][0], target_given)\n",
    "        context_processed.retain_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        grad = context_processed.grad.sign()\n",
    "        if change is None:\n",
    "            change = alpha * grad\n",
    "        else:\n",
    "            change += alpha * grad\n",
    "        context_processed = context_processed + change\n",
    "        context_processed = compute_change(context_processed, original_context, epsilon)\n",
    "    return changes\n",
    "\n",
    "def count_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    return count_list_diff(orig, final)\n",
    "\n",
    "def count_list_diff(orig, final):\n",
    "    changed_entries = 0\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig != final:\n",
    "            changed_entries += 1\n",
    "    return changed_entries\n",
    "    \n",
    "def show_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    changes = []\n",
    "    same = []\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig == final:\n",
    "            changes.append(\"-\")\n",
    "            same.append(final)\n",
    "        else:\n",
    "            changes.append(final)\n",
    "            same.append(\"XX\")\n",
    "    return format_list(changes), format_list(same)\n",
    "\n",
    "def format_list(li):\n",
    "    return f\"[{\", \".join([f'{num:2}' for num in li])}]\"\n",
    "            \n",
    "def print_state(changes_needed, current_trace_num, con, event_chosen, print_path=True, num_iterations=MAX_ITER):\n",
    "    mode_int = 0\n",
    "    changed_num = len(changes_needed)\n",
    "    perturbations_num = count_changes(changes_needed)\n",
    "    result_string = \"\"\n",
    "    if changed_num == 1:\n",
    "        pass\n",
    "    elif changed_num == num_iterations:\n",
    "        mode_int = 3\n",
    "    else:\n",
    "        mode_int = 1\n",
    "        if perturbations_num <= 3:\n",
    "            mode_int = 2\n",
    "            result_string += f\"{current_trace_num}: {format_list(con[0].tolist())} == {event_chosen.tolist()} Changed {{{changed_num}}}, Perturbations {{{perturbations_num}}}\\n\"\n",
    "            if print_path:\n",
    "                for change in changes_needed:\n",
    "                    result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)}{format_list(change[\"changed_to\"])} -> {change['prediction_str']}\\n\"\n",
    "            else:\n",
    "                change_last = changes_needed[-1]\n",
    "                result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)}{format_list(change_last[\"changed_to\"])} -> {change_last['prediction_str']}\\n\"\n",
    "            changed_entries, same_entries = show_changes(changes_needed)\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}== {same_entries}\\n\"\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}-> {changed_entries}\\n\"\n",
    "            result_string += \"\\n\" \n",
    "    return mode_int, result_string\n",
    "\n",
    "def process_traces(alpha=0.01, epsilon=0.5, num_iterations=100, print_path=False):\n",
    "    perturbed_collected_main = []\n",
    "    states = [0, 0, 0, 0]\n",
    "    safe_to_file = \"\"\n",
    "    for current_trace_num in range(len(context_picked)):\n",
    "        con, e = context_picked[current_trace_num], events_picked.unsqueeze(1)[current_trace_num]\n",
    "        con.resize_(1, con.size()[-1])\n",
    "        changes_needed = bim_attack(context_given=con, target_given=e, alpha=alpha, epsilon=epsilon, num_iterations=num_iterations)\n",
    "        mode_int, result_string = print_state(changes_needed, current_trace_num, con, e, print_path=print_path, num_iterations=num_iterations)\n",
    "        print(result_string, end=\"\")\n",
    "        safe_to_file += result_string\n",
    "        if mode_int == 2:\n",
    "            perturbed_collected_main.append((current_trace_num, changes_needed[0]['changed_to'], changes_needed[-1]['changed_to']))\n",
    "        states[mode_int] += 1\n",
    "    print(f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\")\n",
    "    safe_to_file += f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\"\n",
    "    with open(f\"results_trace/length={l}, alpha={alpha}, epsilon={epsilon}, num_iterations={num_iterations}, print_path={print_path}.txt\", \"w\") as f:\n",
    "        f.write(safe_to_file)\n",
    "    return perturbed_collected_main"
   ],
   "id": "aed0a48282625435",
   "outputs": [],
   "execution_count": 339
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:33.215641Z",
     "start_time": "2024-09-23T13:55:33.205957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l = 100\n",
    "chosen_index = 0\n",
    "context_picked = to_cuda(context_test[indices][chosen_index:chosen_index+l].clone().detach())\n",
    "events_picked = to_cuda(events_test[indices][chosen_index:chosen_index+l].clone().detach())\n",
    "labels_picked = to_cuda(labels_test[indices][chosen_index:chosen_index+l].clone().detach())"
   ],
   "id": "5b0deb007a15fad7",
   "outputs": [],
   "execution_count": 340
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:33.218701Z",
     "start_time": "2024-09-23T13:55:33.216528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "v_alpha=0.01\n",
    "v_epsilon=0.5\n",
    "v_num_iterations=100\n",
    "v_print_path=False"
   ],
   "id": "65df71a7a8cdba78",
   "outputs": [],
   "execution_count": 341
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:42.499744Z",
     "start_time": "2024-09-23T13:55:33.219548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "perturbed_collected = process_traces(alpha=v_alpha, epsilon=v_epsilon, num_iterations=v_num_iterations, print_path=v_print_path)    "
   ],
   "id": "cae0ecf8074ff9d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3: [86, 87, 86, 87, 66, 66, 42, 42, 42, 72] == [72] Changed {52}, Perturbations {2}\n",
      "   [86, 87, 86, 87, 66, 66,  1, 42, 42,  1] -> [ 1] 0.234, [15] 0.118, [72] 0.027\n",
      "== [86, 87, 86, 87, 66, 66, XX, 42, 42, XX]\n",
      "-> [- , - , - , - , - , - ,  1, - , - ,  1]\n",
      "\n",
      "5: [87, 86, 87, 66, 66, 42, 42, 42, 72, 72] == [72] Changed {52}, Perturbations {2}\n",
      "   [87, 86, 87, 66, 66, 42,  1, 42, 72,  1] -> [ 1] 0.234, [15] 0.118, [72] 0.037\n",
      "== [87, 86, 87, 66, 66, 42, XX, 42, 72, XX]\n",
      "-> [- , - , - , - , - , - ,  1, - , - ,  1]\n",
      "\n",
      "12: [71, 71, 71, 71, 71, 71, 71, 71, 71, 76] == [79] Changed {52}, Perturbations {2}\n",
      "    [71, 71, 71, 71, 71, 71,  3, 71, 71,  4] -> [71] 0.215, [64] 0.078, [72] 0.072\n",
      " == [71, 71, 71, 71, 71, 71, XX, 71, 71, XX]\n",
      " -> [- , - , - , - , - , - ,  3, - , - ,  4]\n",
      "\n",
      "29: [64, 64, 64, 64, 64, 57, 64, 72, 86, 87] == [86] Changed {52}, Perturbations {3}\n",
      "    [64, 64, 64, 64, 64,  0,  0,  0, 86, 87] -> [66] 0.373, [86] 0.274, [87] 0.216\n",
      " == [64, 64, 64, 64, 64, XX, XX, XX, 86, 87]\n",
      " -> [- , - , - , - , - ,  0,  0,  0, - , - ]\n",
      "\n",
      "37: [64, 72, 86, 87, 86, 87, 87, 86, 87, 86] == [66] Changed {52}, Perturbations {3}\n",
      "    [64, 72,  0, 87,  0, 87, 87,  0, 87, 86] -> [86] 0.425, [66] 0.218, [87] 0.171\n",
      " == [64, 72, XX, 87, XX, 87, 87, XX, 87, 86]\n",
      " -> [- , - ,  0, - ,  0, - , - ,  0, - , - ]\n",
      "\n",
      "47: [89, 89, 89, 89, 89, 89, 89, 64, 72, 72] == [72] Changed {57}, Perturbations {2}\n",
      "    [89, 89, 89, 89, 89, 89,  0, 64,  1, 72] -> [64] 0.392, [72] 0.390, [57] 0.021\n",
      " == [89, 89, 89, 89, 89, 89, XX, 64, XX, 72]\n",
      " -> [- , - , - , - , - , - ,  0, - ,  1, - ]\n",
      "\n",
      "73: [72, 72, 72, 42, 72, 72, 72, 72, 42, 86] == [87] Changed {52}, Perturbations {3}\n",
      "    [72, 72, 72, 42, 72, 72,  1, 72,  0,  4] -> [72] 0.446, [64] 0.036, [44] 0.022\n",
      " == [72, 72, 72, 42, 72, 72, XX, 72, XX, XX]\n",
      " -> [- , - , - , - , - , - ,  1, - ,  0,  4]\n",
      "\n",
      "80: [66, 66, 72, 66, 66, 86, 87, 87, 86, 66] == [66] Changed {52}, Perturbations {3}\n",
      "    [66, 66, 72, 66, 66,  0, 87, 87,  0,  0] -> [ 0] 0.423, [86] 0.087, [72] 0.084\n",
      " == [66, 66, 72, 66, 66, XX, 87, 87, XX, XX]\n",
      " -> [- , - , - , - , - ,  0, - , - ,  0,  0]\n",
      "\n",
      "81: [72, 72, 72, 72, 42, 86, 87, 87, 86, 66] == [66] Changed {52}, Perturbations {3}\n",
      "    [72, 72, 72, 72, 42,  0, 87, 87,  0,  0] -> [ 0] 0.353, [72] 0.120, [86] 0.093\n",
      " == [72, 72, 72, 72, 42, XX, 87, 87, XX, XX]\n",
      " -> [- , - , - , - , - ,  0, - , - ,  0,  0]\n",
      "\n",
      "incorrect=46 changed=39 perturbed=9 timeout=6\n"
     ]
    }
   ],
   "execution_count": 342
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:57:18.123244Z",
     "start_time": "2024-09-23T13:57:18.115676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "def weird_case():\n",
    "    _, _, final_item = perturbed_collected[5]\n",
    "    final_item = to_cuda(torch.tensor(final_item).detach())\n",
    "    final_item.resize_(1, final_item.size()[-1])\n",
    "    output = builder.predict(to_one_hot(final_item))\n",
    "    indices_of_results, print_results = get_results(output)\n",
    "    print(print_results)\n",
    "\n",
    "weird_case()"
   ],
   "id": "96ae1655d1c0c74f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72] 0.393, [64] 0.385, [57] 0.021\n"
     ]
    }
   ],
   "execution_count": 358
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:42.517357Z",
     "start_time": "2024-09-23T13:55:42.507331Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "def to_one_hot(t):\n",
    "    return builder.embedding_one_hot(t)\n",
    "\n",
    "def get_changes_list(s, f):\n",
    "    perturbations_made = []\n",
    "    for i in range(len(s)):\n",
    "        if s[i] != f[i]:\n",
    "            perturbations_made.append((i, f[i]))\n",
    "            \n",
    "    return perturbations_made\n",
    "\n",
    "def get_possible_combinations(perturbations_made):\n",
    "    subsets = []\n",
    "    for r in range(1, len(perturbations_made) + 1):\n",
    "        subsets.extend(itertools.combinations(perturbations_made, r))\n",
    "    result = [list(subset) for subset in subsets]\n",
    "    return result\n",
    "\n",
    "def get_minimum_change_for_perturbation(perturbed_chosen, index_in_list):\n",
    "    i, s, f = perturbed_chosen[index_in_list]\n",
    "    event_target = events_picked[i]\n",
    "    combination_of_perturbation = get_possible_combinations(get_changes_list(s, f))\n",
    "    for combination in combination_of_perturbation:\n",
    "        copy = to_cuda(torch.tensor(s).detach())\n",
    "        for index_of_change, value_of_change in combination:\n",
    "            copy[index_of_change] = value_of_change\n",
    "        copy.resize_(1, copy.size()[-1])\n",
    "        output = builder.predict(to_one_hot(copy))\n",
    "        indices_of_results, _ = get_results(output)\n",
    "        if event_target != indices_of_results[0]:\n",
    "            return copy\n",
    "    # print(f\"ERROR: Could not find a perturbation for {index_in_list} [{i}]\")\n",
    "    # print(f\"       Cannot go from {format_list(s)}\")\n",
    "    # print(f\"                      {format_list(f)}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def process_single(context_chosen):\n",
    "    result_string = \"\"\n",
    "    context_chosen = to_cuda(context_chosen)\n",
    "    output = predict_single(context_chosen)\n",
    "    attentions = [round(x, 5) for x in output[1][0][0].tolist()]\n",
    "    indices_of_results, prediction_str = get_results(output)\n",
    "    result_string += f\"{format_list(context_chosen[0].tolist())} -> {prediction_str}\\n\"\n",
    "    for c, a in zip(context_chosen[0], attentions):\n",
    "        result_string += f\"[{c:2}] {'{:.5f}'.format(a)} \"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "\n",
    "def predict_single(context_chosen):\n",
    "    context_chosen.resize_(1, context_chosen.size()[-1])\n",
    "    context_one_hot = to_one_hot(context_chosen)\n",
    "    return builder.predict(context_one_hot)\n",
    "\n",
    "def predict_single_from_list(list_picked, index_picked):\n",
    "    return predict_single(to_cuda(list_picked[index_picked:index_picked+1].detach()))\n",
    "\n",
    "def analysis(perturbed_chosen, index_picked):\n",
    "    result_string = \"\"\n",
    "    i, s, f = perturbed_chosen[index_picked]\n",
    "    minimum_change_for_perturbation = get_minimum_change_for_perturbation(perturbed_chosen, index_picked)\n",
    "    if minimum_change_for_perturbation is not None:\n",
    "        result_string += f\"Analyzing [{i}], Perturbations [{count_list_diff(s, f)}], Index [{index_picked}]\\n\"\n",
    "        result_string += process_single(torch.tensor(s))\n",
    "        result_string += process_single(minimum_change_for_perturbation)\n",
    "    else:\n",
    "        result_string += f\"Change did not work on [{i}], Index [{index_picked}]\"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "\n",
    "def store(perturbed_chosen):\n",
    "    with open(f\"results_attention/length={l}, alpha={v_alpha}, epsilon={v_epsilon}, num_iterations={v_num_iterations}.txt\", \"w\") as file:\n",
    "        safe_to_file = \"\"\n",
    "        skipped = 0\n",
    "        for perturbed_element in range(len(perturbed_chosen)):\n",
    "            r_string = analysis(perturbed_chosen, perturbed_element)\n",
    "            if \"Change did not work on\" in r_string:\n",
    "                skipped += 1\n",
    "            print(r_string, end=\"\")\n",
    "            safe_to_file += r_string\n",
    "        skipped_str = f\"Had to skip {skipped} out of {len(perturbed_chosen)}\"\n",
    "        print(skipped_str)\n",
    "        safe_to_file += skipped_str\n",
    "        file.write(safe_to_file)"
   ],
   "id": "8584f3097d3d5086",
   "outputs": [],
   "execution_count": 344
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:42.528844Z",
     "start_time": "2024-09-23T13:55:42.519514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "predict_single_from_list(context_test, 1)"
   ],
   "id": "450ce74994acb228",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-6.8765, -6.8174, -7.1251, -7.1295, -6.9701, -7.1554, -6.8575,\n",
       "           -6.8075, -6.5020, -7.2721, -7.0917, -6.9263, -7.0404, -7.0070,\n",
       "           -6.9872, -7.0126, -7.1001, -6.3215, -6.9414, -6.7841, -6.9150,\n",
       "           -7.1430, -7.0604, -7.0142, -6.6135, -6.7930, -6.6675, -7.0499,\n",
       "           -6.8515, -6.1267, -6.7921, -6.7788, -6.8685, -6.9623, -7.1139,\n",
       "           -6.5269, -6.6200, -6.9810, -6.9283, -7.0452, -6.9250, -6.8681,\n",
       "           -6.7176, -6.8632, -6.1814, -6.8988, -7.0167, -7.0005, -6.8409,\n",
       "           -5.3759, -6.8490, -6.8508, -6.9967, -6.8919, -6.9691, -6.9846,\n",
       "           -6.6954, -5.1534, -6.2868, -6.8769, -6.7292, -7.0326, -6.9670,\n",
       "           -6.5998, -3.0556, -7.0751, -7.0083, -6.8997, -7.0593, -6.7141,\n",
       "           -7.1769, -0.1969, -3.8894, -6.8459, -7.2636, -7.4133, -5.9543,\n",
       "           -5.5674, -6.9376, -5.6622, -5.4744, -7.3986, -6.9219, -6.5993,\n",
       "           -6.0573, -6.4426, -6.5565, -6.6639, -7.2940, -7.0215]]],\n",
       "        device='cuda:0', grad_fn=<StackBackward0>),\n",
       " tensor([[[0.0257, 0.0264, 0.0366, 0.0306, 0.0384, 0.0491, 0.0264, 0.1530,\n",
       "           0.0336, 0.5802]]], device='cuda:0', grad_fn=<StackBackward0>))"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 345
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:42.591850Z",
     "start_time": "2024-09-23T13:55:42.530034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "store(perturbed_collected)"
   ],
   "id": "c3abed99e82cd186",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing [3], Perturbations [2], Index [0]\n",
      "[86, 87, 86, 87, 66, 66, 42, 42, 42, 72] -> [72] 0.509, [42] 0.220, [78] 0.023\n",
      "[86] 0.01876 [87] 0.01669 [86] 0.01789 [87] 0.02370 [66] 0.02419 [66] 0.04389 [42] 0.02034 [42] 0.14328 [42] 0.13589 [72] 0.55537 \n",
      "[86, 87, 86, 87, 66, 66, 42, 42, 42,  1] -> [ 1] 0.233, [15] 0.118, [72] 0.027\n",
      "[86] 0.00889 [87] 0.00745 [86] 0.01062 [87] 0.01018 [66] 0.01244 [66] 0.01842 [42] 0.00890 [42] 0.05713 [42] 0.04455 [ 1] 0.82143 \n",
      "\n",
      "Analyzing [5], Perturbations [2], Index [1]\n",
      "[87, 86, 87, 66, 66, 42, 42, 42, 72, 72] -> [72] 0.497, [42] 0.227, [78] 0.023\n",
      "[87] 0.03032 [86] 0.02640 [87] 0.02328 [66] 0.03801 [66] 0.03201 [42] 0.07454 [42] 0.02623 [42] 0.20591 [72] 0.14446 [72] 0.39884 \n",
      "[87, 86, 87, 66, 66, 42, 42, 42, 72,  1] -> [ 1] 0.225, [15] 0.117, [72] 0.038\n",
      "[87] 0.01204 [86] 0.00933 [87] 0.01156 [66] 0.01284 [66] 0.01294 [42] 0.02377 [42] 0.00893 [42] 0.05477 [72] 0.04291 [ 1] 0.81091 \n",
      "\n",
      "Analyzing [12], Perturbations [2], Index [2]\n",
      "[71, 71, 71, 71, 71, 71, 71, 71, 71, 76] -> [79] 0.345, [71] 0.142, [77] 0.107\n",
      "[71] 0.02026 [71] 0.02284 [71] 0.03065 [71] 0.03051 [71] 0.03612 [71] 0.04432 [71] 0.01959 [71] 0.06708 [71] 0.03971 [76] 0.68893 \n",
      "[71, 71, 71, 71, 71, 71, 71, 71, 71,  4] -> [71] 0.214, [64] 0.080, [72] 0.073\n",
      "[71] 0.02329 [71] 0.02279 [71] 0.03162 [71] 0.02986 [71] 0.03401 [71] 0.05185 [71] 0.02110 [71] 0.11251 [71] 0.04091 [ 4] 0.63207 \n",
      "\n",
      "Analyzing [29], Perturbations [3], Index [3]\n",
      "[64, 64, 64, 64, 64, 57, 64, 72, 86, 87] -> [86] 0.385, [66] 0.270, [87] 0.184\n",
      "[64] 0.00713 [64] 0.00691 [64] 0.00861 [64] 0.00909 [64] 0.00854 [57] 0.01308 [64] 0.00755 [72] 0.01739 [86] 0.29736 [87] 0.62434 \n",
      "[64, 64, 64, 64, 64, 57,  0, 72, 86, 87] -> [86] 0.331, [66] 0.323, [87] 0.195\n",
      "[64] 0.00590 [64] 0.00590 [64] 0.00755 [64] 0.00795 [64] 0.00790 [57] 0.01327 [ 0] 0.00706 [72] 0.02345 [86] 0.34147 [87] 0.57956 \n",
      "\n",
      "Analyzing [37], Perturbations [3], Index [4]\n",
      "[64, 72, 86, 87, 86, 87, 87, 86, 87, 86] -> [66] 0.376, [86] 0.295, [87] 0.212\n",
      "[64] 0.00955 [72] 0.00961 [86] 0.01322 [87] 0.01483 [86] 0.01347 [87] 0.03876 [87] 0.01580 [86] 0.12952 [87] 0.50680 [86] 0.24844 \n",
      "[64, 72, 86, 87, 86, 87, 87,  0, 87, 86] -> [86] 0.393, [66] 0.251, [87] 0.181\n",
      "[64] 0.01129 [72] 0.01082 [86] 0.01425 [87] 0.01663 [86] 0.01408 [87] 0.04448 [87] 0.01677 [ 0] 0.15426 [87] 0.48404 [86] 0.23339 \n",
      "\n",
      "Change did not work on [47], Index [5]\n",
      "Analyzing [73], Perturbations [3], Index [6]\n",
      "[72, 72, 72, 42, 72, 72, 72, 72, 42, 86] -> [87] 0.763, [86] 0.079, [72] 0.026\n",
      "[72] 0.01796 [72] 0.01136 [72] 0.01575 [42] 0.01665 [72] 0.01333 [72] 0.02994 [72] 0.00937 [72] 0.03821 [42] 0.11549 [86] 0.73193 \n",
      "[72, 72, 72, 42, 72, 72, 72, 72, 42,  4] -> [72] 0.312, [42] 0.045, [64] 0.043\n",
      "[72] 0.02650 [72] 0.01655 [72] 0.01995 [42] 0.02209 [72] 0.01636 [72] 0.03817 [72] 0.01141 [72] 0.04922 [42] 0.05753 [ 4] 0.74222 \n",
      "\n",
      "Analyzing [80], Perturbations [3], Index [7]\n",
      "[66, 66, 72, 66, 66, 86, 87, 87, 86, 66] -> [66] 0.656, [86] 0.092, [72] 0.057\n",
      "[66] 0.00703 [66] 0.00377 [72] 0.00494 [66] 0.00573 [66] 0.00415 [86] 0.03963 [87] 0.00371 [87] 0.23845 [86] 0.04876 [66] 0.64384 \n",
      "[66, 66, 72, 66, 66, 86, 87, 87, 86,  0] -> [ 0] 0.219, [86] 0.139, [87] 0.108\n",
      "[66] 0.00917 [66] 0.00664 [72] 0.00897 [66] 0.00953 [66] 0.00771 [86] 0.03404 [87] 0.00864 [87] 0.17475 [86] 0.17286 [ 0] 0.56769 \n",
      "\n",
      "Analyzing [81], Perturbations [3], Index [8]\n",
      "[72, 72, 72, 72, 42, 86, 87, 87, 86, 66] -> [66] 0.646, [86] 0.087, [72] 0.065\n",
      "[72] 0.01052 [72] 0.00589 [72] 0.00755 [72] 0.00917 [42] 0.00646 [86] 0.05157 [87] 0.00501 [87] 0.21459 [86] 0.03985 [66] 0.64937 \n",
      "[72, 72, 72, 72, 42, 86, 87, 87, 86,  0] -> [ 0] 0.218, [86] 0.127, [72] 0.108\n",
      "[72] 0.01352 [72] 0.01003 [72] 0.01345 [72] 0.01503 [42] 0.01214 [86] 0.04589 [87] 0.01142 [87] 0.17258 [86] 0.14200 [ 0] 0.56395 \n",
      "\n",
      "Had to skip 1 out of 9\n"
     ]
    }
   ],
   "execution_count": 346
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-23T13:55:43.790322Z",
     "start_time": "2024-09-23T13:55:42.593090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def interpret():\n",
    "    for c, e in zip(context_test, events_test):\n",
    "        cont = to_one_hot(c)\n",
    "        cont = to_cuda(cont.unsqueeze(0))\n",
    "        even = to_cuda(e.reshape(-1, 1))\n",
    "        print(interpreter.predict(X=cont, y=even, verbose=True))\n",
    "        \n",
    "interpret()"
   ],
   "id": "21b0310cc8dabc8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing query:   0%|          | 0/100 [00:00<?, ?it/s]\u001B[A\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 865.78it/s][A\n",
      "\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 621.93it/s]\n",
      "\n",
      "Optimizing query:   0%|          | 0/100 [00:00<?, ?it/s]\u001B[A\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 931.15it/s][A\n",
      "\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 597.14it/s]\n",
      "\n",
      "Optimizing query:   0%|          | 0/100 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n",
      "[3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 936.21it/s][A\n",
      "\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 770.59it/s]\n",
      "\n",
      "Optimizing query:   0%|          | 0/100 [00:00<?, ?it/s]\u001B[A\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 934.16it/s][A\n",
      "\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 1155.77it/s]\n",
      "\n",
      "Optimizing query:   0%|          | 0/100 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n",
      "[3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 933.13it/s][A\n",
      "\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 756.68it/s]\n",
      "\n",
      "Optimizing query:   0%|          | 0/100 [00:00<?, ?it/s]\u001B[A\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 928.32it/s][A\n",
      "\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 754.10it/s]\n",
      "\n",
      "Optimizing query:   0%|          | 0/100 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n",
      "[3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 901.03it/s][A\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[347], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m         even \u001B[38;5;241m=\u001B[39m to_cuda(e\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;28mprint\u001B[39m(interpreter\u001B[38;5;241m.\u001B[39mpredict(X\u001B[38;5;241m=\u001B[39mcont, y\u001B[38;5;241m=\u001B[39meven, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[0;32m----> 8\u001B[0m \u001B[43minterpret\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[347], line 6\u001B[0m, in \u001B[0;36minterpret\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m cont \u001B[38;5;241m=\u001B[39m to_cuda(cont\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m      5\u001B[0m even \u001B[38;5;241m=\u001B[39m to_cuda(e\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43minterpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcont\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meven\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Documents/Thesis/DeepCASE/deepcase_copy/interpreter/interpreter.py:186\u001B[0m, in \u001B[0;36mInterpreter.predict\u001B[0;34m(self, X, y, iterations, batch_size, verbose)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Predict maliciousness of context samples.\u001B[39;00m\n\u001B[1;32m    148\u001B[0m \n\u001B[1;32m    149\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;124;03m        * -3: Closest cluster > epsilon\u001B[39;00m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;66;03m# Get unique samples\u001B[39;00m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;66;03m# X, y, inverse_result = unique_2d(X, y)\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    184\u001B[0m \n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# Compute vectors\u001B[39;00m\n\u001B[0;32m--> 186\u001B[0m vectors, mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattended_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m           \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m           \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[43m   \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthreshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m    \u001B[49m\u001B[43miterations\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43miterations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m     \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# Initialise result\u001B[39;00m\n\u001B[1;32m    196\u001B[0m result \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfull(vectors\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m4\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Thesis/DeepCASE/deepcase_copy/interpreter/interpreter.py:722\u001B[0m, in \u001B[0;36mInterpreter.attended_context\u001B[0;34m(self, X, y, threshold, iterations, batch_size, verbose)\u001B[0m\n\u001B[1;32m    719\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattended_context: Create vectors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    720\u001B[0m \u001B[38;5;66;03m# print(f\"{mask=} {torch.argmax(X[mask], axis=-1).tolist()[0]=}\")\u001B[39;00m\n\u001B[1;32m    721\u001B[0m \u001B[38;5;66;03m# Perform vectorization\u001B[39;00m\n\u001B[0;32m--> 722\u001B[0m X_temp \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[1;32m    723\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m    724\u001B[0m     X_temp \u001B[38;5;241m=\u001B[39m X_temp\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 347
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3160d63d803c8ea7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
