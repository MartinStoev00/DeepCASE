{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-18T11:56:28.883602Z",
     "start_time": "2024-09-18T11:56:25.372961Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from deepcase_copy.context_builder import ContextBuilder\n",
    "from deepcase_copy.preprocessing import Preprocessor\n",
    "\n",
    "builder = ContextBuilder.load('save/builder.save')\n",
    "preprocessor = Preprocessor(\n",
    "    length=10,  # 10 events in context\n",
    "    timeout=86400,  # Ignore events older than 1 day (60*60*24 = 86400 seconds)\n",
    ")\n",
    "context, events, labels, mapping = preprocessor.csv('alerts.csv', verbose=True)\n",
    "\n",
    "# In case no labels are provided, set labels to -1\n",
    "# IMPORTANT: If no labels are provided, make sure to manually set the labels\n",
    "# before calling the interpreter.score_clusters method. Otherwise, this will\n",
    "# raise an exception, because scores == NO_SCORE cannot be computed.\n",
    "if labels is None:\n",
    "    labels = np.full(events.shape[0], -1, dtype=int)\n",
    "\n",
    "# Cast to cuda if available\n",
    "if torch.cuda.is_available():\n",
    "    builder = builder.to('cuda')\n",
    "    events = events.to('cuda')\n",
    "    context = context.to('cuda')\n",
    "\n",
    "\n",
    "# Split into train and test sets (20:80) by time - assuming events are ordered chronologically\n",
    "events_train  = events [:events.shape[0]//5 ]\n",
    "events_test   = events [ events.shape[0]//5:]\n",
    "\n",
    "context_train = context[:events.shape[0]//5 ]\n",
    "context_test  = context[ events.shape[0]//5:]\n",
    "\n",
    "labels_train  = labels [:events.shape[0]//5 ]\n",
    "labels_test   = labels [ events.shape[0]//5:]"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: 100%|██████████| 3353/3353 [00:00<00:00, 4734.52it/s]\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T12:05:55.736197Z",
     "start_time": "2024-09-18T12:05:55.715058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deepcase_copy.interpreter import Interpreter\n",
    "\n",
    "# [[71, 71, 71, 71, 71, 71, 71, 71, 71, 71]] -> [[71]]\n",
    "    \n",
    "interpreter = Interpreter.load('save/interpreter.save', builder)\n",
    "\n",
    "# print(context_picked.shape, even.shape) # torch.Size([1, 10]) torch.Size([1, 1]) -> torch.Size([1, 10, 90]) torch.Size([1, 1])\n",
    "cont = builder.embedding_one_hot(context_test[0])\n",
    "cont = cont.unsqueeze(0)\n",
    "even = events_test[0].reshape(-1, 1)\n",
    "\n",
    "# print(f\"{cont.shape=} {even.shape=}\")\n",
    "\n",
    "# interpreter.predict(X=cont, y=even, verbose=True)\n",
    "cont1 = context_test[0]\n",
    "cont1 = cont1.unsqueeze(0)\n",
    "print(f\"{cont1.shape=}\")\n",
    "torch.unbind(cont1, dim=1)"
   ],
   "id": "93fa6bf4c8e3d982",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cont1.shape=torch.Size([1, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([71], device='cuda:0'),\n",
       " tensor([71], device='cuda:0'),\n",
       " tensor([71], device='cuda:0'),\n",
       " tensor([71], device='cuda:0'),\n",
       " tensor([71], device='cuda:0'),\n",
       " tensor([71], device='cuda:0'),\n",
       " tensor([71], device='cuda:0'),\n",
       " tensor([71], device='cuda:0'),\n",
       " tensor([71], device='cuda:0'),\n",
       " tensor([71], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:38:26.915510Z",
     "start_time": "2024-09-18T11:38:23.651779Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "def get_unique_indices_per_row(tensor):\n",
    "    indices_list = []\n",
    "    row_list = []\n",
    "    indices_list_set = set()\n",
    "    \n",
    "    # Iterate over each row\n",
    "    for row in range(len(tensor)):\n",
    "        curr = tuple(tensor[row].tolist())\n",
    "        \n",
    "        # Check if the current row already exists in row_list using torch.equal\n",
    "        if curr in indices_list_set:\n",
    "            continue\n",
    "        \n",
    "        # Append unique row and its index\n",
    "        row_list.append(curr)\n",
    "        indices_list.append(row)\n",
    "        indices_list_set.add(curr)\n",
    "    \n",
    "    # Return the indices and unique rows\n",
    "    return indices_list, row_list\n",
    "indices, rows = get_unique_indices_per_row(context_test)"
   ],
   "id": "fc89a960fc4f0603",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:38:26.965510Z",
     "start_time": "2024-09-18T11:38:26.916589Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_filtered = torch.tensor(rows)\n",
    "events_filtered = events_test[indices].clone().detach()\n",
    "labels_filtered = labels_test[indices].clone().detach()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    context_filtered = context_filtered.to('cuda')\n",
    "    events_filtered = events_filtered.to('cuda')\n",
    "    labels_filtered = labels_filtered.to('cuda')"
   ],
   "id": "21a3815fdbc48016",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:38:26.970263Z",
     "start_time": "2024-09-18T11:38:26.967158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l = 100\n",
    "chosen_index = 0\n",
    "context_picked = context_filtered[chosen_index:chosen_index+l].detach()\n",
    "events_picked = events_filtered[chosen_index:chosen_index+l].detach()\n",
    "labels_picked = labels_filtered[chosen_index:chosen_index+l]"
   ],
   "id": "17dde4680652c812",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:38:26.988922Z",
     "start_time": "2024-09-18T11:38:26.971535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deepcase_copy.context_builder.loss import LabelSmoothing\n",
    "\n",
    "MAX_ITER = 100\n",
    "\n",
    "def max_to_one(tensor):\n",
    "    max_indices = torch.argmax(tensor, dim=-1, keepdim=True)\n",
    "    result = torch.zeros_like(tensor)\n",
    "    result.scatter_(-1, max_indices, 1.0)\n",
    "    return result\n",
    "\n",
    "def get_results(results):\n",
    "    results_picked = torch.topk(results[0][0][0], 3)\n",
    "    exp = results_picked.values.exp()\n",
    "    res_indices = results_picked.indices\n",
    "    s = []\n",
    "    for j in range(3):\n",
    "        s.append(f\"{format_list([res_indices[j].item()])} {'{:.3f}'.format(exp[j])}\")\n",
    "    return res_indices, \", \".join(s)\n",
    "\n",
    "def compute_change(trace, original, epsilon=0.1):\n",
    "    a = torch.clamp(original - epsilon, min=0)\n",
    "    b = (trace >= a).float() * trace + (trace < a).float() * a\n",
    "    c = (b > original + epsilon).float() * (original + epsilon) + (b <= original + epsilon).float() * b\n",
    "    return max_to_one(c)\n",
    "\n",
    "def bim_attack(context_given, target_given, alpha=0.1, epsilon=0.1, num_iterations=MAX_ITER):\n",
    "    change = None\n",
    "    original_context = builder.embedding_one_hot(context_given)\n",
    "    context_processed = builder.embedding_one_hot(context_given)\n",
    "    criterion = LabelSmoothing(builder.decoder_event.out.out_features, 0.1)    \n",
    "    changes = []\n",
    "    for i in range(num_iterations):\n",
    "        context_processed.requires_grad_(True)\n",
    "        output = builder.predict(context_processed)\n",
    "        indices_of_results, prediction_str = get_results(output)\n",
    "        changes.append({\n",
    "            \"changed_to\": torch.argmax(context_processed, axis=-1).tolist()[0],\n",
    "            \"prediction_str\": prediction_str,\n",
    "        })\n",
    "        if target_given[0] != indices_of_results[0]:\n",
    "            break\n",
    "        loss = criterion(output[0][0], target_given)\n",
    "        context_processed.retain_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        grad = context_processed.grad.sign()\n",
    "        if change is None:\n",
    "            change = alpha * grad\n",
    "        else:\n",
    "            change += alpha * grad\n",
    "        context_processed = context_processed + change\n",
    "        context_processed = compute_change(context_processed, original_context, epsilon)\n",
    "    return changes\n",
    "\n",
    "def count_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    return count_list_diff(orig, final)\n",
    "\n",
    "def count_list_diff(orig, final):\n",
    "    changed_entries = 0\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig != final:\n",
    "            changed_entries += 1\n",
    "    return changed_entries\n",
    "    \n",
    "def show_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    changes = []\n",
    "    same = []\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig == final:\n",
    "            changes.append(\"-\")\n",
    "            same.append(final)\n",
    "        else:\n",
    "            changes.append(final)\n",
    "            same.append(\"XX\")\n",
    "    return format_list(changes), format_list(same)\n",
    "\n",
    "def format_list(li):\n",
    "    return f\"[{\", \".join([f'{num:2}' for num in li])}]\"\n",
    "            \n",
    "def print_state(changes_needed, current_trace_num, con, e, print_path=True, num_iterations=MAX_ITER):\n",
    "    mode_int = 0\n",
    "    changed_num = len(changes_needed)\n",
    "    perturbations_num = count_changes(changes_needed)\n",
    "    result_string = \"\"\n",
    "    if changed_num == 1:\n",
    "        pass\n",
    "    elif changed_num == num_iterations:\n",
    "        mode_int = 3\n",
    "    else:\n",
    "        mode_int = 1\n",
    "        if perturbations_num <= 3:\n",
    "            mode_int = 2\n",
    "            result_string += f\"{current_trace_num}: {format_list(con[0].tolist())} == {e.tolist()} Changed {{{changed_num}}}, Perturbations {{{perturbations_num}}}\\n\"\n",
    "            if print_path:\n",
    "                for change in changes_needed:\n",
    "                    result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)}{format_list(change[\"changed_to\"])} -> {change['prediction_str']}\\n\"\n",
    "            else:\n",
    "                change_last = changes_needed[-1]\n",
    "                result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)}{format_list(change_last[\"changed_to\"])} -> {change_last['prediction_str']}\\n\"\n",
    "            changed_entries, same_entries = show_changes(changes_needed)\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}== {same_entries}\\n\"\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}-> {changed_entries}\\n\"\n",
    "            result_string += \"\\n\" \n",
    "    return mode_int, result_string\n",
    "\n",
    "def process_traces(alpha=0.01, epsilon=0.5, num_iterations=100, print_path=False):\n",
    "    perturbed_collected_main = []\n",
    "    states = [0, 0, 0, 0]\n",
    "    safe_to_file = \"\"\n",
    "    for current_trace_num in range(len(context_picked)):\n",
    "        con, e = context_picked[current_trace_num], events_picked.unsqueeze(1)[current_trace_num]\n",
    "        con.resize_(1, con.size()[-1])\n",
    "        changes_needed = bim_attack(context_given=con, target_given=e, alpha=alpha, epsilon=epsilon, num_iterations=num_iterations)\n",
    "        mode_int, result_string = print_state(changes_needed, current_trace_num, con, e, print_path=print_path, num_iterations=num_iterations)\n",
    "        print(result_string, end=\"\")\n",
    "        safe_to_file += result_string\n",
    "        if mode_int == 2:\n",
    "            perturbed_collected_main.append((current_trace_num, changes_needed[0]['changed_to'], changes_needed[-1]['changed_to']))\n",
    "        states[mode_int] += 1\n",
    "    print(f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\")\n",
    "    safe_to_file += f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\"\n",
    "    with open(f\"results_trace/length={l}, alpha={alpha}, epsilon={epsilon}, num_iterations={num_iterations}, print_path={print_path}.txt\", \"w\") as f:\n",
    "        f.write(safe_to_file)\n",
    "    return perturbed_collected_main"
   ],
   "id": "aed0a48282625435",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:38:26.994033Z",
     "start_time": "2024-09-18T11:38:26.990123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "alpha=0.01\n",
    "epsilon=0.5\n",
    "num_iterations=100\n",
    "print_path=False\n",
    "\n",
    "# perturbed_collected = process_traces(alpha=alpha, epsilon=epsilon, num_iterations=num_iterations, print_path=print_path)"
   ],
   "id": "65df71a7a8cdba78",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:38:26.999079Z",
     "start_time": "2024-09-18T11:38:26.995181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def weird_case():\n",
    "#     _, _, final_item = perturbed_collected[5]\n",
    "#     final_item = torch.tensor(final_item).detach()\n",
    "#     if torch.cuda.is_available():\n",
    "#         final_item = final_item.to('cuda')\n",
    "#     final_item.resize_(1, final_item.size()[-1])\n",
    "#     output = builder.predict(builder.embedding_one_hot(final_item))\n",
    "#     indices_of_results, print_results = get_results(output)\n",
    "#     print(print_results)\n",
    "# \n",
    "# weird_case()"
   ],
   "id": "96ae1655d1c0c74f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:38:27.013177Z",
     "start_time": "2024-09-18T11:38:27.000372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "def get_changes_list(s, f):\n",
    "    perturbations_made = []\n",
    "    for i in range(len(s)):\n",
    "        if s[i] != f[i]:\n",
    "            perturbations_made.append((i, f[i]))\n",
    "            \n",
    "    return perturbations_made\n",
    "\n",
    "def get_possible_combinations(perturbations_made):\n",
    "    subsets = []\n",
    "    for r in range(1, len(perturbations_made) + 1):\n",
    "        subsets.extend(itertools.combinations(perturbations_made, r))\n",
    "    result = [list(subset) for subset in subsets]\n",
    "    return result\n",
    "\n",
    "def get_minimum_change_for_perturbation(perturbed_chosen, index_in_list):\n",
    "    i, s, f = perturbed_chosen[index_in_list]\n",
    "    event_target = events_picked[i]\n",
    "    combination_of_perturbation = get_possible_combinations(get_changes_list(s, f))\n",
    "    for combination in combination_of_perturbation:\n",
    "        copy = torch.tensor(s).detach()\n",
    "        if torch.cuda.is_available():\n",
    "            copy = copy.to('cuda')\n",
    "        for index_of_change, value_of_change in combination:\n",
    "            copy[index_of_change] = value_of_change\n",
    "        copy.resize_(1, copy.size()[-1])\n",
    "        output = builder.predict(builder.embedding_one_hot(copy))\n",
    "        indices_of_results, _ = get_results(output)\n",
    "        if event_target != indices_of_results[0]:\n",
    "            return copy\n",
    "    # print(f\"ERROR: Could not find a perturbation for {index_in_list} [{i}]\")\n",
    "    # print(f\"       Cannot go from {format_list(s)}\")\n",
    "    # print(f\"                      {format_list(f)}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def process_single(context_chosen):\n",
    "    result_string = \"\"\n",
    "    if torch.cuda.is_available():\n",
    "        context_chosen = context_chosen.to('cuda')\n",
    "    output = predict_single(context_chosen)\n",
    "    attentions = [round(x, 5) for x in output[1][0][0].tolist()]\n",
    "    indices_of_results, prediction_str = get_results(output)\n",
    "    result_string += f\"{format_list(context_chosen[0].tolist())} -> {prediction_str}\\n\"\n",
    "    for c, a in zip(context_chosen[0], attentions):\n",
    "        result_string += f\"[{c:2}] {'{:.5f}'.format(a)} \"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "\n",
    "def predict_single(context_chosen):\n",
    "    context_chosen.resize_(1, context_chosen.size()[-1])\n",
    "    context_one_hot = builder.embedding_one_hot(context_chosen)\n",
    "    return builder.predict(context_one_hot)\n",
    "\n",
    "def analysis(perturbed_chosen, index_picked):\n",
    "    result_string = \"\"\n",
    "    i, s, f = perturbed_chosen[index_picked]\n",
    "    minimum_change_for_perturbation = get_minimum_change_for_perturbation(perturbed_chosen, index_picked)\n",
    "    if minimum_change_for_perturbation is not None:\n",
    "        result_string += f\"Analyzing [{i}], Perturbations [{count_list_diff(s, f)}], Index [{index_picked}]\\n\"\n",
    "        result_string += process_single(torch.tensor(s))\n",
    "        result_string += process_single(minimum_change_for_perturbation)\n",
    "    else:\n",
    "        result_string += f\"Change did not work on [{i}], Index [{index_picked}]\"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "\n",
    "def store(perturbed_chosen):\n",
    "    with open(f\"results_attention/length={l}, alpha={alpha}, epsilon={epsilon}, num_iterations={num_iterations}.txt\", \"w\") as file:\n",
    "        safe_to_file = \"\"\n",
    "        for perturbed_element in range(len(perturbed_chosen)):\n",
    "            r_string = analysis(perturbed_chosen, perturbed_element)\n",
    "            print(r_string, end=\"\")\n",
    "            safe_to_file += r_string\n",
    "        file.write(safe_to_file)"
   ],
   "id": "8584f3097d3d5086",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-18T11:38:27.020806Z",
     "start_time": "2024-09-18T11:38:27.014673Z"
    }
   },
   "cell_type": "code",
   "source": "# store(perturbed_collected)",
   "id": "c3abed99e82cd186",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
