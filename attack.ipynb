{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:03.687526Z",
     "start_time": "2024-11-05T00:39:03.500919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from deepcase_copy.context_builder.loss import LabelSmoothing\n",
    "from deepcase_copy.context_builder.context_builder import ContextBuilder\n",
    "from deepcase_copy.interpreter.interpreter import Interpreter\n",
    "from deepcase_copy.interpreter.utils import group_by, sp_unique\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def disable_dropout(m):\n",
    "    if isinstance(m, torch.nn.Dropout):\n",
    "        m.p = 0.0 \n",
    "\n",
    "def to_cuda(item):\n",
    "    if torch.cuda.is_available():\n",
    "        return item.to('cuda')\n",
    "    return item\n",
    "\n",
    "def get_unique_indices_per_row(tensor):\n",
    "    indices_list = []\n",
    "    row_list = []\n",
    "    indices_list_set = set()\n",
    "    for row in range(len(tensor)):\n",
    "        curr = tuple(tensor[row])\n",
    "        if isinstance(tensor, torch.Tensor):\n",
    "            curr = tuple(tensor[row].tolist())\n",
    "        if curr in indices_list_set:\n",
    "            continue\n",
    "        row_list.append(curr)\n",
    "        indices_list.append(row)\n",
    "        indices_list_set.add(curr)\n",
    "    return indices_list\n",
    "\n",
    "def get_unique_indices_per_row_or_file(tensor, f_name):\n",
    "    if os.path.exists(f_name):\n",
    "        return torch.load(f_name)\n",
    "    t = get_unique_indices_per_row(tensor)\n",
    "    torch.save(t, f_name)\n",
    "    return t  \n",
    "\n",
    "ALPHA=0.01\n",
    "EPSILON=0.5\n",
    "MAX_ITER = 100\n",
    "PREDICT_THRESHOLD = 0.2\n",
    "builder = to_cuda(ContextBuilder.load('save/builder.save'))\n",
    "builder.apply(disable_dropout)\n",
    "interpreter = Interpreter.load('save/interpreter.save', builder)\n",
    "criterion = LabelSmoothing(builder.decoder_event.out.out_features, 0.1)\n",
    "attention_query = True\n",
    "\n",
    "with open('save/sequences.save', 'rb') as infile:\n",
    "    data = torch.load(infile)\n",
    "    context = data[\"context\"] # 172572\n",
    "    events  = data[\"events\"]\n",
    "    labels  = data[\"labels\"]\n",
    "    \n",
    "    indices = get_unique_indices_per_row_or_file(context, 'save/context.pt')    \n",
    "    train_indices, test_indices = train_test_split(indices, test_size=0.2, random_state=42, stratify=labels[indices])\n",
    "    \n",
    "    context_train = to_cuda(context[train_indices]) #\n",
    "    context_test  = to_cuda(context[test_indices])  # 4392\n",
    "    \n",
    "    events_train  = to_cuda(events[train_indices])\n",
    "    events_test   = to_cuda(events[test_indices])\n",
    "    \n",
    "    labels_train  = to_cuda(labels[train_indices])\n",
    "    labels_test   = to_cuda(labels[test_indices])\n",
    "\n",
    "def to_one_hot(t):\n",
    "    return builder.embedding_one_hot(t)\n",
    "\n",
    "def max_to_one(tensor):\n",
    "    max_indices = torch.argmax(tensor, dim=-1, keepdim=True)\n",
    "    result = torch.zeros_like(tensor)\n",
    "    result.scatter_(-1, max_indices, 1.0)\n",
    "    return result\n",
    "\n",
    "def to_output(context_chosen):\n",
    "    return builder.predict(to_cuda(to_one_hot(context_chosen)))\n",
    "\n",
    "def get_perturbation_change(trace, original):\n",
    "    a = original - EPSILON\n",
    "    b = (trace >= a).float() * trace + (trace < a).float() * a\n",
    "    c = (b > original + EPSILON).float() * (original + EPSILON) + (b <= original + EPSILON).float() * b\n",
    "    return max_to_one(c)\n",
    "\n",
    "def get_performance(output, num):\n",
    "    results_picked = torch.topk(output[0][0][0], len(output[0][0][0]))\n",
    "    exp = results_picked.values.exp()\n",
    "    res_indices = results_picked.indices\n",
    "    for j in range(len(output[0][0][0])):\n",
    "        if res_indices[j].item() == num:\n",
    "            return exp[j] < PREDICT_THRESHOLD\n",
    "    return False\n",
    "\n",
    "def get_changes_list(start, final):\n",
    "    perturbations_made = []\n",
    "    for i, (s, f) in enumerate(zip(start, final)):\n",
    "        if s != f:\n",
    "            perturbations_made.append((i, f.item()))\n",
    "    return perturbations_made\n",
    "\n",
    "def get_iter_count(context_given, target_given):\n",
    "    for current_trace_num in range(len(context_given)):\n",
    "        con, e = context_given[current_trace_num], target_given.unsqueeze(1)[current_trace_num]\n",
    "        con.resize_(1, con.size()[-1])\n",
    "        for i in range(MAX_ITER):\n",
    "            new_context = bim_no_iter(con, e, i)\n",
    "            if con[0].tolist() != new_context.tolist():\n",
    "                return i\n",
    "    return -1\n",
    "\n",
    "def get_perturbations(context_chosen, event_chosen):\n",
    "    perturbed_collected_main = []\n",
    "    perturbed_indices_main = []\n",
    "    states = [0, 0, 0]\n",
    "    for current_trace_num in tqdm(range(len(context_chosen))):\n",
    "        con, e = context_chosen[current_trace_num], event_chosen.unsqueeze(1)[current_trace_num]\n",
    "        con.resize_(1, con.size()[-1])\n",
    "        if get_performance(to_output(con), e[0]):\n",
    "            states[0] += 1\n",
    "        else:\n",
    "            perturbed_result = bim_attack(con, e)\n",
    "            if perturbed_result is not None:\n",
    "                states[1] += 1\n",
    "                perturbed_collected_main.append(perturbed_result[0])\n",
    "                perturbed_indices_main.append(current_trace_num)\n",
    "            else:\n",
    "                states[2] += 1\n",
    "    return to_cuda(torch.tensor(perturbed_collected_main)), to_cuda(torch.tensor(perturbed_indices_main)), to_cuda(torch.tensor(states))\n",
    "\n",
    "def get_perturbations_or_file(context_chosen, event_chosen):\n",
    "    f_name_perturbed = f\"perturbed/collected/{ALPHA=}, {EPSILON=}.pt\"\n",
    "    f_name_indices = f\"perturbed/indices/{ALPHA=}, {EPSILON=}.pt\"\n",
    "    f_name_distribution = f\"perturbed/distribution/{ALPHA=}, {EPSILON=}.pt\"\n",
    "    if os.path.exists(f_name_perturbed) and os.path.exists(f_name_indices) and os.path.exists(f_name_distribution):\n",
    "        print(f\"Loading {f_name_perturbed}\")\n",
    "        print(f\"Loading {f_name_indices}\")\n",
    "        print(f\"Loading {f_name_distribution}\")\n",
    "        print(torch.load(f_name_distribution))\n",
    "        return torch.load(f_name_perturbed), torch.load(f_name_indices), torch.load(f_name_distribution)\n",
    "    perturb_main, indices_main, result_main = get_perturbations(context_chosen, event_chosen)\n",
    "    torch.save(perturb_main, f_name_perturbed)\n",
    "    torch.save(indices_main, f_name_indices)\n",
    "    torch.save(result_main, f_name_distribution)\n",
    "    print(result_main)\n",
    "    return perturb_main, indices_main, result_main\n",
    "\n",
    "def get_possible_combinations(perturbations_made):\n",
    "    subsets = []\n",
    "    for r_index in range(1, len(perturbations_made)):\n",
    "        subsets.extend(itertools.combinations(perturbations_made, r_index))\n",
    "    result = [list(subset) for subset in subsets]\n",
    "    return result\n",
    "\n",
    "def get_minimum_change_for_perturbation(perturbed_chosen, context_chosen, events_chosen):\n",
    "    for combination in get_possible_combinations(get_changes_list(context_chosen, perturbed_chosen)):\n",
    "        copy = to_cuda(context_chosen.clone().detach())\n",
    "        for index_of_change, value_of_change in combination:\n",
    "            copy[index_of_change] = value_of_change\n",
    "        copy.resize_(1, copy.size()[-1])\n",
    "        if get_performance(to_output(copy), events_chosen):\n",
    "            return copy.squeeze(0)\n",
    "    return perturbed_chosen\n",
    "\n",
    "def get_minimum_change_for_perturbation_attention_query(perturbed_chosen, context_chosen, events_chosen):\n",
    "    trace_combinations = []\n",
    "    for combination in get_possible_combinations(get_changes_list(context_chosen, perturbed_chosen)):\n",
    "        copy = to_cuda(context_chosen.clone().detach())\n",
    "        for index_of_change, value_of_change in combination:\n",
    "            copy[index_of_change] = value_of_change\n",
    "        trace_combinations.append(copy)\n",
    "    if len(trace_combinations) == 0:\n",
    "        return perturbed_chosen\n",
    "    vectors, mask = interpreter.attended_context(\n",
    "        X           = to_one_hot(torch.stack(trace_combinations)),\n",
    "        y           = to_cuda(torch.full((len(trace_combinations),1), events_chosen.item())),\n",
    "        iterations  = 100\n",
    "    )\n",
    "    mask_indices = torch.where(~mask)[0]\n",
    "    chosen = perturbed_chosen\n",
    "    if len(mask_indices) != 0:\n",
    "        chosen = trace_combinations[mask_indices[0]]\n",
    "    return chosen\n",
    "    \n",
    "def get_shortcuts(perturbed_chosen, context_chosen, events_chosen):\n",
    "    pick_list = []\n",
    "    for perturbed_element  in tqdm(zip(perturbed_chosen, context_chosen, events_chosen), total=len(perturbed_chosen)):\n",
    "        pick_list.append(get_minimum_change_for_perturbation(*perturbed_element))\n",
    "    return to_cuda(torch.stack(pick_list))\n",
    "\n",
    "def get_shortcuts_or_file(perturbed_chosen, context_chosen, events_chosen):\n",
    "    f_name = f\"perturbed/minimized/{ALPHA=}, {EPSILON=}.pt\"\n",
    "    if os.path.exists(f_name):\n",
    "        print(f\"Loading {f_name}\")\n",
    "        return torch.load(f_name)\n",
    "    pick_list = get_shortcuts(perturbed_chosen, context_chosen, events_chosen)\n",
    "    torch.save(pick_list, f_name)\n",
    "    return pick_list\n",
    "    \n",
    "def get_shortcuts_attention_query(perturbed_chosen, context_chosen, events_chosen):\n",
    "    pick_list = []\n",
    "    for perturbed_element  in tqdm(zip(perturbed_chosen, context_chosen, events_chosen), total=len(perturbed_chosen)):\n",
    "        pick_list.append(get_minimum_change_for_perturbation_attention_query(*perturbed_element))\n",
    "    return to_cuda(torch.stack(pick_list))\n",
    "\n",
    "def get_shortcuts_attention_query_or_file(perturbed_chosen, context_chosen, events_chosen):\n",
    "    f_name = f\"perturbed/minimized_attention_query/{ALPHA=}, {EPSILON=}.pt\"\n",
    "    if os.path.exists(f_name):\n",
    "        print(f\"Loading {f_name}\")\n",
    "        return torch.load(f_name)\n",
    "    pick_list = get_shortcuts_attention_query(perturbed_chosen, context_chosen, events_chosen)\n",
    "    torch.save(pick_list, f_name)\n",
    "    return pick_list\n",
    "    \n",
    "def get_dist(trace_dist):\n",
    "    tensor_tuples = [tuple(t) if len(t) > 0 else (t.item(),) for t in trace_dist]\n",
    "    index_groups = {}\n",
    "    for idx, tensor_tuple in enumerate(tensor_tuples):\n",
    "        if tensor_tuple not in index_groups:\n",
    "            index_groups[tensor_tuple] = []\n",
    "        index_groups[tensor_tuple].append(idx)\n",
    "    sorted_groups = sorted(index_groups.items(), key=lambda x: (len(x[0]), x[0]))\n",
    "    return [idx for _, indices_l in sorted_groups for idx in indices_l]\n",
    "    \n",
    "def get_matrix(context_chosen, shortcut_chosen, perturb_chosen):\n",
    "    matrix = [[0] * 10 for _ in range(10)]\n",
    "    for c, s, p in zip(context_chosen, shortcut_chosen, perturb_chosen):\n",
    "        cs = len(get_changes_list(c, s)) - 1\n",
    "        cp = len(get_changes_list(c, p)) - 1\n",
    "        matrix[cp][cs] += 1\n",
    "    for m in matrix:\n",
    "        print(f\"[{\", \".join([f'{num:3}' for num in m])}]\")\n",
    "    \n",
    "def bim_attack(context_chosen, event_chosen):\n",
    "    change = 0\n",
    "    original_context = to_cuda(to_one_hot(context_chosen).clone().detach())\n",
    "    context_processed = to_cuda(to_one_hot(context_chosen).clone().detach())\n",
    "    for iteration in range(MAX_ITER):\n",
    "        context_processed.requires_grad_(True)\n",
    "        output = builder.predict(context_processed)\n",
    "        if get_performance(output, event_chosen[0]):\n",
    "            return torch.argmax(context_processed, dim=-1).tolist()[0], iteration\n",
    "        loss = criterion(output[0][0], event_chosen)\n",
    "        context_processed.retain_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        grad = context_processed.grad.sign()\n",
    "        change += ALPHA * grad\n",
    "        context_processed = get_perturbation_change(context_processed + change, original_context)\n",
    "    return None\n",
    "    \n",
    "def format_results(results):\n",
    "    results_picked = torch.topk(results[0][0][0], 3)\n",
    "    exp = results_picked.values.exp()\n",
    "    res_indices = results_picked.indices\n",
    "    return \", \".join([f\"{format_list([res_indices[j].item()])} {'{:.3f}'.format(exp[j])}\" for j in range(3)])\n",
    "  \n",
    "def format_changes(start, final):\n",
    "    changes = []\n",
    "    same = []\n",
    "    for s, f in zip(start, final):\n",
    "        if s == f:\n",
    "            changes.append(\"-\")\n",
    "            same.append(final)\n",
    "        else:\n",
    "            changes.append(f)\n",
    "            same.append(\"XX\")\n",
    "    return format_list(changes), format_list(same)\n",
    "\n",
    "def format_list(li):\n",
    "    return f\"[{\", \".join([f'{num:2}' for num in li])}]\"\n",
    "            \n",
    "def format_trace_prediction(current_trace_num, trace):\n",
    "    start = \" \"*(len(str(current_trace_num)) + 2)\n",
    "    trace = to_cuda(trace.clone().detach())\n",
    "    trace.resize_(1, trace.size()[-1])\n",
    "    return f\"{start}{format_list(trace)} -> {format_results(to_output(trace))}\\n\"\n",
    "            \n",
    "def format_perturbation(perturb_chosen, perturb_int, context_chosen, event_chosen, current_trace_num):\n",
    "    result_string = f\"{current_trace_num}: {format_list(context_chosen[0].tolist())} == {event_chosen.tolist()} Changed [{perturb_int}], Perturbations [{len(get_changes_list(context_chosen, perturb_chosen))}]\\n\"\n",
    "    result_string += format_trace_prediction(current_trace_num, context_chosen)    \n",
    "    result_string += format_trace_prediction(current_trace_num, perturb_chosen)    \n",
    "    changed_entries, same_entries = format_changes(context_chosen, perturb_chosen)\n",
    "    result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}== {same_entries}\\n{\" \"*(len(str(current_trace_num)) - 1)}-> {changed_entries}\\n\\n\"\n",
    "    return result_string\n",
    "\n",
    "def format_attention(x_mask, context_mask, vectors, neighbours, distance, scores):\n",
    "    data_collected = [] \n",
    "    for i in range(len(context_mask)):\n",
    "        l_value = torch.tensor(vectors[context_mask][i].toarray()[0])\n",
    "        l_indices = torch.nonzero(l_value, as_tuple=False).squeeze(1)\n",
    "        data_collected.append({\n",
    "            \"trace\": x_mask[context_mask][i],\n",
    "            \"indices\": l_indices.tolist(),\n",
    "            \"value\": l_value[l_indices].tolist(),\n",
    "            \"neighbour\": f\"{{{neighbours[i]:5}; {scores[i]} | {'{:.4f}'.format(distance[i][0]) }}}\"\n",
    "        })\n",
    "    res_str = \"\"\n",
    "    for s in get_dist(list(map(lambda x: x[\"indices\"], data_collected))):\n",
    "        local_l = data_collected[s]\n",
    "        local_list = list(zip(local_l[\"indices\"], local_l[\"value\"]))\n",
    "        res = f\"{format_list(local_l[\"trace\"].tolist())} -> \"\n",
    "        for index, value in sorted(local_list, key=lambda x: x[1], reverse=True):\n",
    "            res += f\"[{f'{index:2}'}]: {'{:.4f}'.format(value)} \"\n",
    "        res_str += res + f\"{\" \"*(150 - len(res))} {local_l[\"neighbour\"]}\\n\"\n",
    "    return res_str\n",
    "\n",
    "def show_clusters(x, y):\n",
    "    vectors, mask = interpreter.attended_context(to_one_hot(x), y.reshape(-1, 1))\n",
    "    indices_y = group_by(y[mask].reshape(-1, 1).cpu().numpy(), lambda e: e.data.tobytes(),)\n",
    "    with open(f\"results/cluster/alpha={ALPHA}, epsilon={EPSILON}.txt\", \"w\") as file:\n",
    "        for event, context_mask in indices_y:\n",
    "            event = ord(event.decode('ascii')[0])   \n",
    "            if event not in interpreter.tree:\n",
    "                file.write(f\"{\"<\"*50}[{event}]{\">\"*50}\\n\")\n",
    "                continue\n",
    "            file.write(f\"{\"=\"*50}[{event}]{\"=\"*50}\\n\")\n",
    "            vectors_, inverse, _ = sp_unique(vectors[context_mask])\n",
    "            distance, neighbours = interpreter.tree[event].query(\n",
    "                X               = vectors_.toarray(),\n",
    "                return_distance = True,\n",
    "                dualtree        = vectors_.shape[0] >= 1e3, # Optimization\n",
    "            )\n",
    "            neighbours = interpreter.tree[event].get_arrays()[1][neighbours][:, 0]\n",
    "            scores = np.asarray([interpreter.labels[event][neighbour] for neighbour in neighbours])\n",
    "            file.write(format_attention(x[mask], context_mask, vectors, neighbours[inverse], distance[inverse], scores[inverse]) + \"\\n\")\n",
    "\n",
    "def interpret(context_passed, events_passed, threshold=0.2):\n",
    "    c = to_one_hot(context_passed)\n",
    "    e = events_passed.reshape(-1, 1)\n",
    "    interpreter.threshold = threshold\n",
    "    if not attention_query:\n",
    "        return interpreter.predict(X=c, y=e, iterations=0)\n",
    "    return interpreter.predict(X=c, y=e)\n",
    "\n",
    "def bim_no_iter(context_chosen, event_chosen, iters):\n",
    "    context_processed = to_cuda(to_one_hot(context_chosen).clone().detach())\n",
    "    original_context = to_cuda(to_one_hot(context_chosen).clone().detach())\n",
    "    context_processed.requires_grad_(True)\n",
    "    output = builder.predict(context_processed)\n",
    "    loss = criterion(output[0][0], event_chosen)\n",
    "    context_processed.retain_grad()\n",
    "    loss.backward(retain_graph=True)\n",
    "    context_processed = get_perturbation_change(context_processed + (ALPHA * context_processed.grad.sign()) * iters, original_context)\n",
    "    return to_cuda(torch.tensor(torch.argmax(context_processed, dim=-1).tolist()[0]))\n",
    "\n",
    "def run_bim(context_to_process, events_to_process):\n",
    "    perturbed_collected_main = []\n",
    "    perturbed_indices_main = []\n",
    "    states = [0, 0, 0]\n",
    "    length = len(context_to_process)\n",
    "    iters = tqdm(range(length))\n",
    "    iters_to_flip = get_iter_count(context_to_process, events_to_process)\n",
    "    for current_trace_num in iters:\n",
    "        con, e = context_to_process[current_trace_num], events_to_process.unsqueeze(1)[current_trace_num]\n",
    "        con.resize_(1, con.size()[-1])\n",
    "        if get_performance(con, e[0]):\n",
    "            states[0] += 1\n",
    "            continue\n",
    "        perturbed = bim_no_iter(con, e, iters=iters_to_flip)\n",
    "        perturbed.resize_(1, perturbed.size()[-1])\n",
    "        if get_performance(perturbed, e[0]):\n",
    "            perturbed_collected_main.append(perturbed.tolist()[0])\n",
    "            perturbed_indices_main.append(current_trace_num)\n",
    "            states[1] += 1\n",
    "        else:\n",
    "            states[2] += 1\n",
    "    print(f\"incorrect={states[0]} perturbed={states[1]} timeout={states[2]}\")\n",
    "    return to_cuda(torch.tensor(perturbed_collected_main)), to_cuda(torch.tensor(perturbed_indices_main))"
   ],
   "id": "aed0a48282625435",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:03.695263Z",
     "start_time": "2024-11-05T00:39:03.689254Z"
    }
   },
   "cell_type": "code",
   "source": "pd.Series(labels_test.cpu()).value_counts().sort_index()",
   "id": "a018199d3bba7e91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      65\n",
       "2     454\n",
       "3    3864\n",
       "5       9\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:05.245020Z",
     "start_time": "2024-11-05T00:39:03.752411Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res_normal = interpret(context_test, events_test)\n",
    "pd.Series(res_normal).value_counts().sort_index()"
   ],
   "id": "9080c2f76b7cefc0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0     467\n",
       "-1.0     490\n",
       " 2.0     378\n",
       " 3.0    3025\n",
       " 5.0      32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:05.258648Z",
     "start_time": "2024-11-05T00:39:05.246557Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(labels_test.cpu(), res_normal, labels=[-3.0, -1.0, 1.0, 2.0, 3.0, 5.0])",
   "id": "36aff409622aed33",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [  25,   13,    0,    0,    0,   27],\n",
       "       [  21,   55,    0,  378,    0,    0],\n",
       "       [ 420,  419,    0,    0, 3025,    0],\n",
       "       [   1,    3,    0,    0,    0,    5]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:05.267174Z",
     "start_time": "2024-11-05T00:39:05.260088Z"
    }
   },
   "cell_type": "code",
   "source": "perturbed_collected, perturbed_indices, perturb_distribution = get_perturbations_or_file(context_test, events_test)",
   "id": "7505db07e1f3f663",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading perturbed/collected/ALPHA=0.01, EPSILON=0.5.pt\n",
      "Loading perturbed/indices/ALPHA=0.01, EPSILON=0.5.pt\n",
      "Loading perturbed/distribution/ALPHA=0.01, EPSILON=0.5.pt\n",
      "tensor([1074, 2983,  335], device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 83
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:06.368816Z",
     "start_time": "2024-11-05T00:39:05.269865Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Unique:\", len(get_unique_indices_per_row(perturbed_collected)))\n",
    "res_perturbed_only = interpret(perturbed_collected, events_test[perturbed_indices])\n",
    "pd.Series(res_perturbed_only).value_counts().sort_index()"
   ],
   "id": "917381ce1abdffbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique: 2386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.0     118\n",
       "-1.0    2745\n",
       " 2.0      16\n",
       " 3.0     104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 84
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:07.181379Z",
     "start_time": "2024-11-05T00:39:06.370005Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(labels_test[perturbed_indices].cpu(), interpret(context_test[perturbed_indices], events_test[perturbed_indices]), labels=[-3.0, -1.0, 1.0, 2.0, 3.0, 5.0])",
   "id": "1e91ea3cf1e14ab9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [  18,    0,    0,    0,    0,   17],\n",
       "       [   1,    0,    0,  275,    0,    0],\n",
       "       [ 205,    0,    0,    0, 2466,    0],\n",
       "       [   0,    0,    0,    0,    0,    1]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:07.191310Z",
     "start_time": "2024-11-05T00:39:07.182606Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(labels_test[perturbed_indices].cpu(), res_perturbed_only, labels=[-3.0, -1.0, 1.0, 2.0, 3.0, 5.0])",
   "id": "246f21acaefaf781",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [   2,   33,    0,    0,    0,    0],\n",
       "       [   9,  251,    0,   16,    0,    0],\n",
       "       [ 107, 2460,    0,    0,  104,    0],\n",
       "       [   0,    1,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:08.100856Z",
     "start_time": "2024-11-05T00:39:07.192564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_test_original_perturbed = context_test.clone().detach()\n",
    "context_test_original_perturbed[perturbed_indices] = perturbed_collected\n",
    "c_indices_perturbed = get_unique_indices_per_row(context_test_original_perturbed)\n",
    "res_combined_perturbed = interpret(context_test_original_perturbed[c_indices_perturbed], events_test[c_indices_perturbed])\n",
    "pd.Series(res_combined_perturbed).value_counts().sort_index()"
   ],
   "id": "9363911580e357cc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0     356\n",
       "-1.0    2640\n",
       " 2.0     110\n",
       " 3.0     660\n",
       " 5.0      14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:08.110783Z",
     "start_time": "2024-11-05T00:39:08.101987Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(labels_test[c_indices_perturbed].cpu(), res_combined_perturbed, labels=[-3.0, -1.0, 1.0, 2.0, 3.0, 5.0])",
   "id": "db6da10a71c9a8c9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [   9,   40,    0,    0,    0,   10],\n",
       "       [  28,  252,    0,  110,    0,    0],\n",
       "       [ 318, 2345,    0,    0,  660,    0],\n",
       "       [   1,    3,    0,    0,    0,    4]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:08.116527Z",
     "start_time": "2024-11-05T00:39:08.111887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "perturbed_minimized = get_shortcuts_or_file(\n",
    "    perturbed_collected, \n",
    "    context_test[perturbed_indices], \n",
    "    events_test[perturbed_indices]\n",
    ")"
   ],
   "id": "c02f053c4b600123",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading perturbed/minimized/ALPHA=0.01, EPSILON=0.5.pt\n"
     ]
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:09.993407Z",
     "start_time": "2024-11-05T00:39:08.119716Z"
    }
   },
   "cell_type": "code",
   "source": "get_matrix(context_test[perturbed_indices], perturbed_minimized, perturbed_collected)",
   "id": "3fa418f6d57b5c4e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50,   0,   0,   0,   0,   0,   0,   0,   0,   0]\n",
      "[109,   2,   0,   0,   0,   0,   0,   0,   0,   0]\n",
      "[249,   7,   2,   0,   0,   0,   0,   0,   0,   0]\n",
      "[299,   9,   0,   0,   0,   0,   0,   0,   0,   0]\n",
      "[353,  10,   2,   1,   0,   0,   0,   0,   0,   0]\n",
      "[386,  15,   0,   0,   1,   0,   0,   0,   0,   0]\n",
      "[356,   3,   0,   0,   0,   0,   0,   0,   0,   0]\n",
      "[395,   0,   0,   0,   0,   0,   0,   0,   0,   0]\n",
      "[346,   1,   0,   0,   1,   0,   0,   0,   0,   0]\n",
      "[386,   0,   0,   0,   0,   0,   0,   0,   0,   0]\n"
     ]
    }
   ],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:11.020222Z",
     "start_time": "2024-11-05T00:39:09.994755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Unique:\", len(get_unique_indices_per_row(perturbed_minimized)))\n",
    "res_perturbed_shortcuts = interpret(perturbed_minimized, events_test[perturbed_indices])\n",
    "pd.Series(res_perturbed_shortcuts).value_counts().sort_index()"
   ],
   "id": "49d4a4460e92260f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique: 2960\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.0    1398\n",
       "-1.0     393\n",
       " 2.0     153\n",
       " 3.0    1033\n",
       " 5.0       6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:11.029521Z",
     "start_time": "2024-11-05T00:39:11.021509Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(labels_test[perturbed_indices].cpu(), res_perturbed_shortcuts, labels=[-3.0, -1.0, 1.0, 2.0, 3.0, 5.0])",
   "id": "693068227b2cd425",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [  29,    0,    0,    0,    0,    6],\n",
       "       [  89,   34,    0,  153,    0,    0],\n",
       "       [1279,  359,    0,    0, 1033,    0],\n",
       "       [   1,    0,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:12.385963Z",
     "start_time": "2024-11-05T00:39:11.030777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_test_original_perturbed_shortcuts = context_test.clone().detach()\n",
    "context_test_original_perturbed_shortcuts[perturbed_indices] = perturbed_minimized\n",
    "c_indices_perturbed_shortcuts = get_unique_indices_per_row(context_test_original_perturbed_shortcuts)\n",
    "res_combined_perturbed_shortcuts = interpret(context_test_original_perturbed_shortcuts[c_indices_perturbed_shortcuts], events_test[c_indices_perturbed_shortcuts])\n",
    "pd.Series(res_combined_perturbed_shortcuts).value_counts().sort_index()"
   ],
   "id": "470009850f317626",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0    1638\n",
       "-1.0     873\n",
       " 2.0     251\n",
       " 3.0    1581\n",
       " 5.0      20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:12.395180Z",
     "start_time": "2024-11-05T00:39:12.387128Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(labels_test[c_indices_perturbed_shortcuts].cpu(), res_combined_perturbed_shortcuts, labels=[-3.0, -1.0, 1.0, 2.0, 3.0, 5.0])",
   "id": "9c0870f42857e1e2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [  36,   13,    0,    0,    0,   16],\n",
       "       [ 109,   87,    0,  251,    0,    0],\n",
       "       [1491,  770,    0,    0, 1581,    0],\n",
       "       [   2,    3,    0,    0,    0,    4]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:12.400462Z",
     "start_time": "2024-11-05T00:39:12.396358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "perturbed_minimized_attention_query = get_shortcuts_attention_query_or_file(\n",
    "    perturbed_collected,\n",
    "    context_test[perturbed_indices], \n",
    "    events_test[perturbed_indices]\n",
    ")"
   ],
   "id": "1aae9ea5669d056c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading perturbed/minimized_attention_query/ALPHA=0.01, EPSILON=0.5.pt\n"
     ]
    }
   ],
   "execution_count": 95
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:14.481221Z",
     "start_time": "2024-11-05T00:39:12.401726Z"
    }
   },
   "cell_type": "code",
   "source": "get_matrix(context_test[perturbed_indices], perturbed_minimized_attention_query, perturbed_collected)",
   "id": "6dfd91b04a66445a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 50,   0,   0,   0,   0,   0,   0,   0,   0,   0]\n",
      "[ 40,  71,   0,   0,   0,   0,   0,   0,   0,   0]\n",
      "[ 70,  53, 135,   0,   0,   0,   0,   0,   0,   0]\n",
      "[ 56,  47,  56, 149,   0,   0,   0,   0,   0,   0]\n",
      "[ 55,  33,  65,  58, 155,   0,   0,   0,   0,   0]\n",
      "[ 41,  31,  41,  61,  61, 167,   0,   0,   0,   0]\n",
      "[ 34,  14,  43,  31,  36,  49, 152,   0,   0,   0]\n",
      "[ 19,  25,  27,  25,  21,  46,  56, 176,   0,   0]\n",
      "[ 27,  24,  36,  15,  17,  20,  37,  72, 100,   0]\n",
      "[ 19,  14,  26,  24,  31,  45,  27,  63,  61,  76]\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:15.131209Z",
     "start_time": "2024-11-05T00:39:14.482455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Unique:\", len(get_unique_indices_per_row(perturbed_minimized_attention_query)))\n",
    "res_perturbed_shortcuts = interpret(perturbed_minimized_attention_query, events_test[perturbed_indices])\n",
    "pd.Series(res_perturbed_shortcuts).value_counts().sort_index()"
   ],
   "id": "6e81461aaca6aff2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique: 2780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.0     118\n",
       "-1.0    2745\n",
       " 2.0      16\n",
       " 3.0     104\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:15.139351Z",
     "start_time": "2024-11-05T00:39:15.132361Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(labels_test[perturbed_indices].cpu(), res_perturbed_shortcuts, labels=[-3.0, -1.0, 1.0, 2.0, 3.0, 5.0])",
   "id": "a54863531ff990d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [   2,   33,    0,    0,    0,    0],\n",
       "       [   9,  251,    0,   16,    0,    0],\n",
       "       [ 107, 2460,    0,    0,  104,    0],\n",
       "       [   0,    1,    0,    0,    0,    0]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:16.289017Z",
     "start_time": "2024-11-05T00:39:15.140409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_test_original_perturbed_shortcuts_attention_query = context_test.clone().detach()\n",
    "context_test_original_perturbed_shortcuts_attention_query[perturbed_indices] = perturbed_minimized_attention_query\n",
    "c_indices_perturbed_shortcuts_attention_query = get_unique_indices_per_row(context_test_original_perturbed_shortcuts_attention_query)\n",
    "res_combined_perturbed_shortcuts_attention_query = interpret(context_test_original_perturbed_shortcuts_attention_query[c_indices_perturbed_shortcuts_attention_query], events_test[c_indices_perturbed_shortcuts_attention_query])\n",
    "pd.Series(res_combined_perturbed_shortcuts_attention_query).value_counts().sort_index()"
   ],
   "id": "70f00f41b82b98a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.0     356\n",
       "-1.0    3032\n",
       " 2.0     109\n",
       " 3.0     661\n",
       " 5.0      14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:16.300957Z",
     "start_time": "2024-11-05T00:39:16.290375Z"
    }
   },
   "cell_type": "code",
   "source": "confusion_matrix(labels_test[c_indices_perturbed_shortcuts_attention_query].cpu(), res_combined_perturbed_shortcuts_attention_query, labels=[-3.0, -1.0, 1.0, 2.0, 3.0, 5.0])",
   "id": "3b989efc5a70112c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0],\n",
       "       [   9,   46,    0,    0,    0,   10],\n",
       "       [  28,  278,    0,  109,    0,    0],\n",
       "       [ 318, 2704,    0,    0,  661,    0],\n",
       "       [   1,    4,    0,    0,    0,    4]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T00:39:19.426590Z",
     "start_time": "2024-11-05T00:39:16.302400Z"
    }
   },
   "cell_type": "code",
   "source": "show_clusters(context_test, events_test)",
   "id": "212a9376d02c1f00",
   "outputs": [],
   "execution_count": 101
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
