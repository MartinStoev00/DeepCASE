{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-04T10:40:25.630455Z",
     "start_time": "2024-10-04T10:40:25.577370Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from deepcase_copy.context_builder.context_builder import ContextBuilder\n",
    "from deepcase_copy.interpreter.interpreter import Interpreter\n",
    "from deepcase_copy.context_builder.loss import LabelSmoothing\n",
    "\n",
    "def disable_dropout(m):\n",
    "    if isinstance(m, torch.nn.Dropout):\n",
    "        m.p = 0.0 \n",
    "\n",
    "def to_cuda(item):\n",
    "    if torch.cuda.is_available():\n",
    "        return item.to('cuda')\n",
    "    return item\n",
    "\n",
    "def get_unique_indices_per_row(tensor, f_name):\n",
    "    if os.path.exists(f_name):\n",
    "        return torch.load(f_name)\n",
    "    indices_list = []\n",
    "    row_list = []\n",
    "    indices_list_set = set()\n",
    "    for row in range(len(tensor)):\n",
    "        curr = tuple(tensor[row].tolist())\n",
    "        if curr in indices_list_set:\n",
    "            continue\n",
    "        row_list.append(curr)\n",
    "        indices_list.append(row)\n",
    "        indices_list_set.add(curr)\n",
    "    t = torch.tensor(indices_list)\n",
    "    torch.save(t, f_name)\n",
    "    return t  \n",
    "\n",
    "LENGTH=10\n",
    "ALPHA=0.01\n",
    "EPSILON=0.5\n",
    "MAX_ITER = 100\n",
    "PERTURB_THRESHOLD = 3\n",
    "builder = to_cuda(ContextBuilder.load('save/builder.save'))\n",
    "builder.apply(disable_dropout)\n",
    "interpreter = Interpreter.load('save/interpreter.save', builder)\n",
    "criterion = LabelSmoothing(builder.decoder_event.out.out_features, 0.1)    \n",
    "\n",
    "with open('save/sequences.save', 'rb') as infile:\n",
    "    data = torch.load(infile)\n",
    "    events  = data[\"events\"]\n",
    "    context = data[\"context\"] # 172572\n",
    "    labels  = data[\"labels\"]\n",
    "    mapping = data[\"mapping\"]\n",
    "    \n",
    "    events_train  = to_cuda(events [:events.shape[0]//5 ])\n",
    "    events_test   = to_cuda(events [ events.shape[0]//5:])\n",
    "    \n",
    "    context_train = to_cuda(context[:events.shape[0]//5 ]) \n",
    "    context_test  = to_cuda(context[ events.shape[0]//5:]) \n",
    "    \n",
    "    labels_train  = to_cuda(labels [:events.shape[0]//5 ])  # 34514\n",
    "    labels_test   = to_cuda(labels [ events.shape[0]//5:])  # 138058\n",
    "    \n",
    "    indices_train = get_unique_indices_per_row(context_train, 'save/context_train.pt')  # 10425\n",
    "    indices_test  = get_unique_indices_per_row(context_test, 'save/context_test.pt')    # 12982\n",
    "    \n",
    "    clusters        = pd.read_csv('save/clusters.csv')['clusters'].values\n",
    "    clusters_train  = clusters [:events.shape[0]//5 ]\n",
    "    clusters_test   = clusters [ events.shape[0]//5:]\n",
    "    \n",
    "    prediction_label        = pd.read_csv('save/prediction.csv')['labels'].values\n",
    "    prediction_label_train  = prediction_label [:events.shape[0]//5 ]\n",
    "    prediction_label_test   = prediction_label [ events.shape[0]//5:]"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:40:25.634455Z",
     "start_time": "2024-10-04T10:40:25.632131Z"
    }
   },
   "cell_type": "code",
   "source": "# pd.Series(prediction_label_test[indices_test]).value_counts().sort_index()",
   "id": "8553ff768af293c7",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:40:25.639664Z",
     "start_time": "2024-10-04T10:40:25.635526Z"
    }
   },
   "cell_type": "code",
   "source": "# context_test[indices_test][0], events_test[indices_test][0], labels_test[indices_test][0], prediction_label_test[indices_test][0], clusters_test[indices_test][0]",
   "id": "f13666629333480c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:40:25.643740Z",
     "start_time": "2024-10-04T10:40:25.641609Z"
    }
   },
   "cell_type": "code",
   "source": "# pd.Series(clusters_test[indices_test]).value_counts().sort_index()",
   "id": "8c9b570d31d952ae",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:40:25.665095Z",
     "start_time": "2024-10-04T10:40:25.644982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def to_one_hot(t):\n",
    "    return builder.embedding_one_hot(t)\n",
    "\n",
    "def max_to_one(tensor):\n",
    "    max_indices = torch.argmax(tensor, dim=-1, keepdim=True)\n",
    "    result = torch.zeros_like(tensor)\n",
    "    result.scatter_(-1, max_indices, 1.0)\n",
    "    return result\n",
    "\n",
    "def get_results(results):\n",
    "    results_picked = torch.topk(results[0][0][0], 3)\n",
    "    exp = results_picked.values.exp()\n",
    "    res_indices = results_picked.indices\n",
    "    s = []\n",
    "    for j in range(3):\n",
    "        s.append(f\"{format_list([res_indices[j].item()])} {'{:.3f}'.format(exp[j])}\")\n",
    "    return res_indices, \", \".join(s)\n",
    "\n",
    "def compute_change(trace, original, epsilon=EPSILON):\n",
    "    a = original - epsilon\n",
    "    b = (trace >= a).float() * trace + (trace < a).float() * a\n",
    "    c = (b > original + epsilon).float() * (original + epsilon) + (b <= original + epsilon).float() * b\n",
    "    return max_to_one(c), c\n",
    "\n",
    "def bim_attack(context_given, target_given, alpha=0.1, epsilon=EPSILON, num_iterations=MAX_ITER, training=True):\n",
    "    change = None\n",
    "    original_context = to_cuda(to_one_hot(context_given).clone().detach())\n",
    "    context_processed = to_cuda(to_one_hot(context_given).clone().detach())\n",
    "    changes = []\n",
    "    computed_change_collected = []\n",
    "    for i in range(num_iterations):\n",
    "        context_processed.requires_grad_(True)\n",
    "        output = builder.predict(context_processed, training=training)\n",
    "        indices_of_results, prediction_str = get_results(output)\n",
    "        changes.append({\n",
    "            \"changed_to\": torch.argmax(context_processed, axis=-1).tolist()[0],\n",
    "            \"prediction_str\": prediction_str,\n",
    "        })\n",
    "        if target_given[0] != indices_of_results[0]:\n",
    "            break\n",
    "        loss = criterion(output[0][0], target_given)\n",
    "        context_processed.retain_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        grad = context_processed.grad.sign()\n",
    "        if change is None:\n",
    "            change = alpha * grad\n",
    "        else:\n",
    "            change += alpha * grad\n",
    "        context_processed = context_processed + change\n",
    "        context_processed, computed_change = compute_change(context_processed, original_context, epsilon)\n",
    "        computed_change_collected.append(computed_change)\n",
    "    return changes, computed_change_collected\n",
    "\n",
    "def count_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    return count_list_diff(orig, final)\n",
    "\n",
    "def count_list_diff(orig, final):\n",
    "    changed_entries = 0\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig != final:\n",
    "            changed_entries += 1\n",
    "    return changed_entries\n",
    "    \n",
    "def show_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    changes = []\n",
    "    same = []\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig == final:\n",
    "            changes.append(\"-\")\n",
    "            same.append(final)\n",
    "        else:\n",
    "            changes.append(final)\n",
    "            same.append(\"XX\")\n",
    "    return format_list(changes), format_list(same)\n",
    "\n",
    "def format_list(li):\n",
    "    return f\"[{\", \".join([f'{num:2}' for num in li])}]\"\n",
    "            \n",
    "def format_line(current_trace_num, changes_needed, i):\n",
    "    start = \" \"*(len(str(current_trace_num)) + 2)\n",
    "    if i != 0:\n",
    "        if len(str(current_trace_num)) == 1:\n",
    "            start = f'{i:<3}'\n",
    "        elif len(str(current_trace_num)) == 2:\n",
    "            start = f'{i:<4}'\n",
    "        elif len(str(current_trace_num)) == 3:\n",
    "            start = f'{i:<5}'\n",
    "        elif len(str(current_trace_num)) == 4:\n",
    "            start = f'{i:<6}'\n",
    "        else:\n",
    "            start = f'{i:<7}'\n",
    "        b = list(start)\n",
    "        b[len(str(i))] = '<'\n",
    "        start = ''.join(b)\n",
    "    return f\"{start}{format_list(changes_needed[i][\"changed_to\"])} -> {changes_needed[i]['prediction_str']}\\n\"\n",
    "            \n",
    "def print_state(changes_needed, current_trace_num, con, event_chosen, change_collected, print_path=True, include_change=True, num_iterations=MAX_ITER):\n",
    "    mode_int = 0\n",
    "    changed_num = len(changes_needed)\n",
    "    perturbations_num = count_changes(changes_needed)\n",
    "    result_string = \"\"\n",
    "    if changed_num == 1:\n",
    "        pass\n",
    "    elif changed_num == num_iterations:\n",
    "        mode_int = 3\n",
    "    else:\n",
    "        mode_int = 1\n",
    "        if perturbations_num <= PERTURB_THRESHOLD:\n",
    "            mode_int = 2\n",
    "            result_string += f\"{current_trace_num}: {format_list(con[0].tolist())} == {event_chosen.tolist()} Changed {{{changed_num}}}, Perturbations {{{perturbations_num}}}\\n\"\n",
    "            if print_path:\n",
    "                for i in range(len(changes_needed)):\n",
    "                    result_string += format_line(current_trace_num, changes_needed, i)                    \n",
    "                    if include_change:\n",
    "                        if i is not len(changes_needed) - 1:\n",
    "                            result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)} {change_collected[i]=}\\n\"\n",
    "            else:\n",
    "                for i in range(len(changes_needed)):\n",
    "                    if i == 0 or (changes_needed[i][\"changed_to\"] != changes_needed[i-1][\"changed_to\"] and i != len(changes_needed) - 1):\n",
    "                        result_string += format_line(current_trace_num, changes_needed, i)\n",
    "                change_last = changes_needed[-1]\n",
    "                result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)}{format_list(change_last[\"changed_to\"])} -> {change_last['prediction_str']}\\n\"\n",
    "            changed_entries, same_entries = show_changes(changes_needed)\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}== {same_entries}\\n\"\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}-> {changed_entries}\\n\"\n",
    "            result_string += \"\\n\" \n",
    "    return mode_int, result_string\n",
    "\n",
    "def process_traces(context_to_process, events_to_process, alpha=ALPHA, epsilon=EPSILON, num_iterations=MAX_ITER, length=LENGTH, chosen_index=0, print_path=False, include_change=False, write_to_file=False, print_result=False, training=True):\n",
    "    perturbed_collected_main = []\n",
    "    states = [0, 0, 0, 0]\n",
    "    safe_to_file = \"\"\n",
    "    iters = range(length)\n",
    "    if not print_result:\n",
    "        iters = tqdm(iters)\n",
    "    for current_trace_num in iters:\n",
    "        con, e = context_to_process[chosen_index:chosen_index+length][current_trace_num], events_to_process[chosen_index:chosen_index+length].unsqueeze(1)[current_trace_num]\n",
    "        con.resize_(1, con.size()[-1])\n",
    "        changes_needed, change_collected = bim_attack(context_given=con, target_given=e, alpha=alpha, epsilon=epsilon, num_iterations=num_iterations, training=training)\n",
    "        mode_int, result_string = print_state(changes_needed, current_trace_num, con, e, change_collected, print_path=print_path, include_change=include_change, num_iterations=num_iterations)\n",
    "        if print_result:\n",
    "            print(result_string, end=\"\")\n",
    "        safe_to_file += result_string\n",
    "        if mode_int == 2:\n",
    "            perturbed_collected_main.append((current_trace_num, changes_needed[0]['changed_to'], changes_needed[-1]['changed_to']))\n",
    "        states[mode_int] += 1\n",
    "    print(f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\")\n",
    "    safe_to_file += f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\"\n",
    "    if write_to_file:\n",
    "        with open(f\"results_trace/length={length}, alpha={alpha}, epsilon={epsilon}, num_iterations={num_iterations}, print_path={print_path} include_change={include_change}.txt\", \"w\") as f:\n",
    "            f.write(safe_to_file)\n",
    "    return perturbed_collected_main\n",
    "\n",
    "def inspect_index(index_inspected, context_l, events_l, training=True):\n",
    "    local_context_picked = to_cuda(context_l[index_inspected:index_inspected+1].clone().detach())\n",
    "    local_events_picked = to_cuda(events_l[index_inspected:index_inspected+1].clone().detach())\n",
    "    process_traces(local_context_picked, local_events_picked, alpha=ALPHA, epsilon=EPSILON, num_iterations=MAX_ITER, print_path=True, include_change=False, write_to_file=True, print_result=True, training=training)"
   ],
   "id": "aed0a48282625435",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:40:25.678099Z",
     "start_time": "2024-10-04T10:40:25.666043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_changes_list(s, f):\n",
    "    perturbations_made = []\n",
    "    for i in range(len(s)):\n",
    "        if s[i] != f[i]:\n",
    "            perturbations_made.append((i, f[i]))\n",
    "            \n",
    "    return perturbations_made\n",
    "\n",
    "def get_possible_combinations(perturbations_made):\n",
    "    subsets = []\n",
    "    for r in range(1, len(perturbations_made) + 1):\n",
    "        subsets.extend(itertools.combinations(perturbations_made, r))\n",
    "    result = [list(subset) for subset in subsets]\n",
    "    return result\n",
    "\n",
    "def get_minimum_change_for_perturbation(perturbed_chosen, events_picked, index_in_list, training=True):\n",
    "    i, s, f = perturbed_chosen[index_in_list]\n",
    "    event_target = events_picked[i]\n",
    "    combination_of_perturbation = get_possible_combinations(get_changes_list(s, f))\n",
    "    for i in range(len(combination_of_perturbation)):\n",
    "        combination = combination_of_perturbation[i]\n",
    "        copy = to_cuda(torch.tensor(s).detach())\n",
    "        for index_of_change, value_of_change in combination:\n",
    "            copy[index_of_change] = value_of_change\n",
    "        copy.resize_(1, copy.size()[-1])\n",
    "        output = builder.predict(to_one_hot(copy), training=training)\n",
    "        indices_of_results, _ = get_results(output)\n",
    "        if event_target != indices_of_results[0]:\n",
    "            return copy, f\"Shortcut: {combination_of_perturbation[-1]} -> {combination}\\n\" if i == len(combination_of_perturbation) - 1 and len(combination_of_perturbation) != 1 else \"\"\n",
    "    # print(f\"ERROR: Could not find a perturbation for {index_in_list} [{i}]\")\n",
    "    # print(f\"       Cannot go from {format_list(s)}\")\n",
    "    # print(f\"                      {format_list(f)}\")\n",
    "    \n",
    "    return None, False\n",
    "\n",
    "def process_single(context_chosen, training=True):\n",
    "    result_string = \"\"\n",
    "    context_chosen = to_cuda(context_chosen)\n",
    "    output = predict_single(context_chosen, training=training)\n",
    "    attentions = [round(x, 5) for x in output[1][0][0].tolist()]\n",
    "    indices_of_results, prediction_str = get_results(output)\n",
    "    result_string += f\"{format_list(context_chosen[0].tolist())} -> {prediction_str}\\n\"\n",
    "    for c, a in zip(context_chosen[0], attentions):\n",
    "        result_string += f\"[{c:2}] {'{:.5f}'.format(a)} \"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "    \n",
    "def predict_single(context_chosen, training=True):\n",
    "    context_chosen.resize_(1, context_chosen.size()[-1])\n",
    "    context_one_hot = to_one_hot(context_chosen)\n",
    "    return builder.predict(context_one_hot, training=training)\n",
    "\n",
    "def predict_single_from_list(list_picked, index_picked):\n",
    "    return predict_single(to_cuda(list_picked[index_picked:index_picked+1].detach()))\n",
    "\n",
    "def analysis(perturbed_chosen, events_picked, index_picked, training=True):\n",
    "    result_string = \"\"\n",
    "    i, s, f = perturbed_chosen[index_picked]\n",
    "    minimum_change_for_perturbation, final_combination = get_minimum_change_for_perturbation(perturbed_chosen, events_picked, index_picked, training=training)\n",
    "    if minimum_change_for_perturbation is not None:\n",
    "        result_string += f\"Analyzing [{i}], Perturbations [{count_list_diff(s, f)}], Index [{index_picked}]\\n\"\n",
    "        result_string += process_single(torch.tensor(s), training=training)\n",
    "        result_string += process_single(minimum_change_for_perturbation, training=training)\n",
    "        result_string += final_combination\n",
    "    else:\n",
    "        result_string += f\"Change did not work on [{i}], Index [{index_picked}]\\n\"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "\n",
    "def store(perturbed_chosen, events_picked, length=LENGTH, chosen_index=0, alpha=ALPHA, epsilon=EPSILON, num_iterations=MAX_ITER, training=True, print_details=False):\n",
    "    with open(f\"results_attention/length={length}, alpha={alpha}, epsilon={epsilon}, num_iterations={num_iterations}.txt\", \"w\") as file:\n",
    "        safe_to_file = \"\"\n",
    "        skipped = 0\n",
    "        shortcuts = 0\n",
    "        for perturbed_element in range(len(perturbed_chosen)):\n",
    "            r_string = analysis(perturbed_chosen, events_picked[chosen_index:chosen_index+length], perturbed_element, training=training)\n",
    "            if \"Change did not work on\" in r_string:\n",
    "                skipped += 1\n",
    "            if \"Shortcut\" in r_string:\n",
    "                shortcuts += 1\n",
    "            if print_details:\n",
    "                print(r_string, end=\"\")\n",
    "            safe_to_file += r_string\n",
    "        skipped_str = f\"Results: {skipped=}/{shortcuts=} out of {length}\"\n",
    "        print(skipped_str)\n",
    "        safe_to_file += skipped_str\n",
    "        file.write(safe_to_file)"
   ],
   "id": "a7a3e3cbb4303508",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:40:27.084547Z",
     "start_time": "2024-10-04T10:40:25.679455Z"
    }
   },
   "cell_type": "code",
   "source": "perturbed_collected = process_traces(context_test[indices_test], events_test[indices_test])  ",
   "id": "833015caf1eaac91",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001B[A\n",
      " 10%|█         | 1/10 [00:00<00:01,  5.25it/s]\u001B[A\n",
      " 30%|███       | 3/10 [00:00<00:00,  8.64it/s]\u001B[A\n",
      " 40%|████      | 4/10 [00:00<00:00,  7.34it/s]\u001B[A\n",
      " 50%|█████     | 5/10 [00:00<00:00,  6.82it/s]\u001B[A\n",
      " 60%|██████    | 6/10 [00:00<00:00,  6.51it/s]\u001B[A\n",
      " 70%|███████   | 7/10 [00:01<00:00,  6.26it/s]\u001B[A\n",
      " 80%|████████  | 8/10 [00:01<00:00,  6.10it/s]\u001B[A\n",
      "100%|██████████| 10/10 [00:01<00:00,  7.15it/s][A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect=2 changed=6 perturbed=2 timeout=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:40:27.104670Z",
     "start_time": "2024-10-04T10:40:27.085718Z"
    }
   },
   "cell_type": "code",
   "source": "store(perturbed_collected, events_picked=events_test[indices_test])",
   "id": "c3abed99e82cd186",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: skipped=0/shortcuts=0 out of 10\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T10:41:45.900057Z",
     "start_time": "2024-10-04T10:41:44.196604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def interpret():\n",
    "    c = to_one_hot(context_test[indices_test])\n",
    "    e = events_test[indices_test].reshape(-1, 1)\n",
    "    return interpreter.predict(X=c, y=e, verbose=True)\n",
    "\n",
    "res_i = interpret()\n",
    "pd.Series(res_i).value_counts().sort_index()"
   ],
   "id": "21b0310cc8dabc8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimizing query:   0%|          | 0/1300 [00:00<?, ?it/s]\u001B[A\n",
      "Optimizing query:   6%|▌         | 77/1300 [00:00<00:01, 768.84it/s]\u001B[A\n",
      "Optimizing query:  12%|█▏        | 154/1300 [00:00<00:01, 708.20it/s]\u001B[A\n",
      "Optimizing query:  17%|█▋        | 226/1300 [00:00<00:01, 702.31it/s]\u001B[A\n",
      "Optimizing query:  24%|██▎       | 307/1300 [00:00<00:01, 741.46it/s]\u001B[A\n",
      "Optimizing query:  30%|███       | 393/1300 [00:00<00:01, 781.76it/s]\u001B[A\n",
      "Optimizing query:  36%|███▋      | 472/1300 [00:00<00:01, 780.13it/s]\u001B[A\n",
      "Optimizing query:  43%|████▎     | 553/1300 [00:00<00:00, 788.87it/s]\u001B[A\n",
      "Optimizing query:  49%|████▉     | 635/1300 [00:00<00:00, 796.19it/s]\u001B[A\n",
      "Optimizing query:  55%|█████▌    | 715/1300 [00:00<00:00, 795.71it/s]\u001B[A\n",
      "Optimizing query:  62%|██████▏   | 801/1300 [00:01<00:00, 795.01it/s]\u001B[A\n",
      "Optimizing query:  69%|██████▊   | 891/1300 [00:01<00:00, 825.80it/s]\u001B[A\n",
      "Optimizing query:  75%|███████▍  | 974/1300 [00:01<00:00, 769.77it/s]\u001B[A\n",
      "Optimizing query:  81%|████████  | 1052/1300 [00:01<00:00, 770.55it/s]\u001B[A\n",
      "Optimizing query:  87%|████████▋ | 1130/1300 [00:01<00:00, 766.90it/s]\u001B[A\n",
      "Optimizing query: 100%|██████████| 1300/1300 [00:01<00:00, 782.45it/s]\u001B[A\n",
      "\n",
      "Predicting      : 100%|██████████| 49/49 [00:00<00:00, 108055.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-2.0    11852\n",
       "-1.0     1130\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
