{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-01T11:19:30.260238Z",
     "start_time": "2024-10-01T11:19:30.163277Z"
    }
   },
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from deepcase_copy.context_builder.context_builder import ContextBuilder\n",
    "from deepcase_copy.interpreter.interpreter import Interpreter\n",
    "from deepcase_copy.context_builder.loss import LabelSmoothing\n",
    "\n",
    "def to_cuda(item):\n",
    "    if torch.cuda.is_available():\n",
    "        return item.to('cuda')\n",
    "    return item\n",
    "\n",
    "builder = to_cuda(ContextBuilder.load('save/builder.save'))\n",
    "interpreter = Interpreter.load('save/interpreter.save', builder)\n",
    "criterion = LabelSmoothing(builder.decoder_event.out.out_features, 0.1)    \n",
    "\n",
    "with open('save/sequences.save', 'rb') as infile:\n",
    "    data = torch.load(infile)\n",
    "    events  = data[\"events\"]\n",
    "    context = data[\"context\"]\n",
    "    labels  = data[\"labels\"]\n",
    "    mapping = data[\"mapping\"]\n",
    "    \n",
    "    events_train  = to_cuda(events [:events.shape[0]//5 ])\n",
    "    events_test   = to_cuda(events [ events.shape[0]//5:])\n",
    "    \n",
    "    context_train = to_cuda(context[:events.shape[0]//5 ])\n",
    "    context_test  = to_cuda(context[ events.shape[0]//5:])\n",
    "    \n",
    "    labels_train  = to_cuda(labels [:events.shape[0]//5 ])\n",
    "    labels_test   = to_cuda(labels [ events.shape[0]//5:])"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T11:19:39.255556Z",
     "start_time": "2024-10-01T11:19:39.223639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def disable_dropout(m):\n",
    "    if isinstance(m, torch.nn.Dropout):\n",
    "        m.p = 0.0  # Disable dropout by setting probability to 0\n",
    "\n",
    "def predict_single_eval(index_inspected, iterations=1):\n",
    "    \n",
    "    local_context_picked = to_cuda(context_test[index_inspected:index_inspected+1].clone().detach())\n",
    "    local_events_picked = to_cuda(events_test[index_inspected:index_inspected+1].clone().detach())\n",
    "    con, e = local_context_picked[0], local_events_picked.unsqueeze(1)[0]\n",
    "    print(f\"con={con.tolist()}, e={e.tolist()}\")\n",
    "    con.resize_(1, con.size()[-1])\n",
    "    con = builder.embedding_one_hot(con)\n",
    "    builder.apply(disable_dropout)\n",
    "    for _ in range(iterations):\n",
    "        output = builder.forward(con, training=True)\n",
    "        print(get_results(output)[1])\n",
    "        loss = criterion.forward(output[0][0], e)\n",
    "        loss.backward()\n",
    "\n",
    "predict_single_eval(300, 5)"
   ],
   "id": "ea2a896f176db917",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "con=[66, 72, 66, 66, 78, 78, 72, 72, 18, 18], e=[18]\n",
      "[18] 0.584, [72] 0.158, [64] 0.015\n",
      "[18] 0.584, [72] 0.158, [64] 0.015\n",
      "[18] 0.584, [72] 0.158, [64] 0.015\n",
      "[18] 0.584, [72] 0.158, [64] 0.015\n",
      "[18] 0.584, [72] 0.158, [64] 0.015\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T12:05:05.448197Z",
     "start_time": "2024-10-01T12:05:01.605726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_unique_indices_per_row(tensor):\n",
    "    indices_list = []\n",
    "    row_list = []\n",
    "    indices_list_set = set()\n",
    "    \n",
    "    for row in range(len(tensor)):\n",
    "        curr = tuple(tensor[row].tolist())\n",
    "        \n",
    "        if curr in indices_list_set:\n",
    "            continue\n",
    "        \n",
    "        row_list.append(curr)\n",
    "        indices_list.append(row)\n",
    "        indices_list_set.add(curr)\n",
    "    \n",
    "    return indices_list, row_list\n",
    "indices, rows = get_unique_indices_per_row(context_test)"
   ],
   "id": "fc89a960fc4f0603",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T12:11:07.105934Z",
     "start_time": "2024-10-01T12:11:07.024139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MAX_ITER = 100\n",
    "PERTURB_THRESHOLD = 3\n",
    "\n",
    "def to_one_hot(t):\n",
    "    return builder.embedding_one_hot(t)\n",
    "\n",
    "def max_to_one(tensor):\n",
    "    max_indices = torch.argmax(tensor, dim=-1, keepdim=True)\n",
    "    result = torch.zeros_like(tensor)\n",
    "    result.scatter_(-1, max_indices, 1.0)\n",
    "    return result\n",
    "\n",
    "def get_results(results):\n",
    "    results_picked = torch.topk(results[0][0][0], 3)\n",
    "    exp = results_picked.values.exp()\n",
    "    res_indices = results_picked.indices\n",
    "    s = []\n",
    "    for j in range(3):\n",
    "        s.append(f\"{format_list([res_indices[j].item()])} {'{:.3f}'.format(exp[j])}\")\n",
    "    return res_indices, \", \".join(s)\n",
    "\n",
    "def compute_change(trace, original, epsilon=0.1):\n",
    "    a = original - epsilon\n",
    "    b = (trace >= a).float() * trace + (trace < a).float() * a\n",
    "    c = (b > original + epsilon).float() * (original + epsilon) + (b <= original + epsilon).float() * b\n",
    "    return max_to_one(c), c\n",
    "\n",
    "def bim_attack(context_given, target_given, alpha=0.1, epsilon=0.1, num_iterations=MAX_ITER, training=True):\n",
    "    change = None\n",
    "    original_context = to_one_hot(context_given)\n",
    "    context_processed = to_one_hot(context_given)\n",
    "    changes = []\n",
    "    computed_change_collected = []\n",
    "    for i in range(num_iterations):\n",
    "        context_processed.requires_grad_(True)\n",
    "        output = builder.predict(context_processed, training=training)\n",
    "        indices_of_results, prediction_str = get_results(output)\n",
    "        changes.append({\n",
    "            \"changed_to\": torch.argmax(context_processed, axis=-1).tolist()[0],\n",
    "            \"prediction_str\": prediction_str,\n",
    "        })\n",
    "        if target_given[0] != indices_of_results[0]:\n",
    "            break\n",
    "        loss = criterion(output[0][0], target_given)\n",
    "        context_processed.retain_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        grad = context_processed.grad.sign()\n",
    "        if change is None:\n",
    "            change = alpha * grad\n",
    "        else:\n",
    "            change += alpha * grad\n",
    "        context_processed = context_processed + change\n",
    "        context_processed, computed_change = compute_change(context_processed, original_context, epsilon)\n",
    "        computed_change_collected.append(computed_change)\n",
    "    return changes, computed_change_collected\n",
    "\n",
    "def count_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    return count_list_diff(orig, final)\n",
    "\n",
    "def count_list_diff(orig, final):\n",
    "    changed_entries = 0\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig != final:\n",
    "            changed_entries += 1\n",
    "    return changed_entries\n",
    "    \n",
    "def show_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    changes = []\n",
    "    same = []\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig == final:\n",
    "            changes.append(\"-\")\n",
    "            same.append(final)\n",
    "        else:\n",
    "            changes.append(final)\n",
    "            same.append(\"XX\")\n",
    "    return format_list(changes), format_list(same)\n",
    "\n",
    "def format_list(li):\n",
    "    return f\"[{\", \".join([f'{num:2}' for num in li])}]\"\n",
    "            \n",
    "def format_line(current_trace_num, changes_needed, i):\n",
    "    start = \" \"*(len(str(current_trace_num)) + 2)\n",
    "    if i != 0:\n",
    "        if len(str(current_trace_num)) == 1:\n",
    "            start = f'{i:<3}'\n",
    "        elif len(str(current_trace_num)) == 2:\n",
    "            start = f'{i:<4}'\n",
    "        elif len(str(current_trace_num)) == 3:\n",
    "            start = f'{i:<5}'\n",
    "        elif len(str(current_trace_num)) == 4:\n",
    "            start = f'{i:<6}'\n",
    "        else:\n",
    "            start = f'{i:<7}'\n",
    "        b = list(start)\n",
    "        b[len(str(i))] = '<'\n",
    "        start = ''.join(b)\n",
    "    return f\"{start}{format_list(changes_needed[i][\"changed_to\"])} -> {changes_needed[i]['prediction_str']}\\n\"\n",
    "            \n",
    "def print_state(changes_needed, current_trace_num, con, event_chosen, change_collected, print_path=True, include_change=True, num_iterations=MAX_ITER):\n",
    "    mode_int = 0\n",
    "    changed_num = len(changes_needed)\n",
    "    perturbations_num = count_changes(changes_needed)\n",
    "    result_string = \"\"\n",
    "    if changed_num == 1:\n",
    "        pass\n",
    "    elif changed_num == num_iterations:\n",
    "        mode_int = 3\n",
    "    else:\n",
    "        mode_int = 1\n",
    "        if perturbations_num <= PERTURB_THRESHOLD:\n",
    "            mode_int = 2\n",
    "            result_string += f\"{current_trace_num}: {format_list(con[0].tolist())} == {event_chosen.tolist()} Changed {{{changed_num}}}, Perturbations {{{perturbations_num}}}\\n\"\n",
    "            if print_path:\n",
    "                for i in range(len(changes_needed)):\n",
    "                    result_string += format_line(current_trace_num, changes_needed, i)                    \n",
    "                    if include_change:\n",
    "                        if i is not len(changes_needed) - 1:\n",
    "                            result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)} {change_collected[i]=}\\n\"\n",
    "            else:\n",
    "                for i in range(len(changes_needed)):\n",
    "                    if i == 0 or (changes_needed[i][\"changed_to\"] != changes_needed[i-1][\"changed_to\"] and i != len(changes_needed) - 1):\n",
    "                        result_string += format_line(current_trace_num, changes_needed, i)\n",
    "                change_last = changes_needed[-1]\n",
    "                result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)}{format_list(change_last[\"changed_to\"])} -> {change_last['prediction_str']}\\n\"\n",
    "            changed_entries, same_entries = show_changes(changes_needed)\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}== {same_entries}\\n\"\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}-> {changed_entries}\\n\"\n",
    "            result_string += \"\\n\" \n",
    "    return mode_int, result_string\n",
    "\n",
    "def process_traces(context_to_process, events_to_process, alpha=0.01, epsilon=0.5, num_iterations=100, print_path=False, include_change=False, write_to_file=False, print_result=False, training=True):\n",
    "    perturbed_collected_main = []\n",
    "    states = [0, 0, 0, 0]\n",
    "    safe_to_file = \"\"\n",
    "    iters = range(len(context_to_process))\n",
    "    if not print_result:\n",
    "        iters = tqdm(iters)\n",
    "    for current_trace_num in iters:\n",
    "        con, e = context_to_process[current_trace_num], events_to_process.unsqueeze(1)[current_trace_num]\n",
    "        con.resize_(1, con.size()[-1])\n",
    "        changes_needed, change_collected = bim_attack(context_given=con, target_given=e, alpha=alpha, epsilon=epsilon, num_iterations=num_iterations, training=training)\n",
    "        mode_int, result_string = print_state(changes_needed, current_trace_num, con, e, change_collected, print_path=print_path, include_change=include_change, num_iterations=num_iterations)\n",
    "        if print_result:\n",
    "            print(result_string, end=\"\")\n",
    "        safe_to_file += result_string\n",
    "        if mode_int == 2:\n",
    "            perturbed_collected_main.append((current_trace_num, changes_needed[0]['changed_to'], changes_needed[-1]['changed_to']))\n",
    "        states[mode_int] += 1\n",
    "    print(f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\")\n",
    "    safe_to_file += f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\"\n",
    "    if write_to_file:\n",
    "        with open(f\"results_trace/length={l}, alpha={alpha}, epsilon={epsilon}, num_iterations={num_iterations}, print_path={print_path} include_change={include_change}.txt\", \"w\") as f:\n",
    "            f.write(safe_to_file)\n",
    "    return perturbed_collected_main\n",
    "\n",
    "def inspect_index(index_inspected, training=True):\n",
    "    local_context_picked = to_cuda(context_test[indices][index_inspected:index_inspected+1].clone().detach())\n",
    "    local_events_picked = to_cuda(events_test[indices][index_inspected:index_inspected+1].clone().detach())\n",
    "    process_traces(local_context_picked, local_events_picked, alpha=0.01, epsilon=0.5, num_iterations=1000, print_path=True, include_change=False, write_to_file=True, print_result=True, training=training)  "
   ],
   "id": "aed0a48282625435",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T12:11:08.574881Z",
     "start_time": "2024-10-01T12:11:08.534973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l = 1000\n",
    "chosen_index = 0\n",
    "v_alpha = 0.01\n",
    "v_epsilon = 0.5\n",
    "v_num_iterations = 100\n",
    "context_picked = to_cuda(context_test[indices][chosen_index:chosen_index+l].clone().detach())\n",
    "events_picked = to_cuda(events_test[indices][chosen_index:chosen_index+l].clone().detach())\n",
    "labels_picked = to_cuda(labels_test[indices][chosen_index:chosen_index+l].clone().detach())"
   ],
   "id": "3265e4ec5d85eca9",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T12:14:14.399105Z",
     "start_time": "2024-10-01T12:11:31.563363Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "perturbed_collected = process_traces(\n",
    "    context_picked, \n",
    "    events_picked, \n",
    "    alpha=v_alpha, \n",
    "    epsilon=v_epsilon, \n",
    "    num_iterations=v_num_iterations, \n",
    "    print_path=False, \n",
    "    include_change=False, \n",
    "    write_to_file=True, \n",
    "    print_result=False, \n",
    "    training=True\n",
    ")  "
   ],
   "id": "833015caf1eaac91",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [02:42<00:00,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect=345 changed=522 perturbed=57 timeout=76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T12:14:14.416015Z",
     "start_time": "2024-10-01T12:14:14.400627Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "def get_changes_list(s, f):\n",
    "    perturbations_made = []\n",
    "    for i in range(len(s)):\n",
    "        if s[i] != f[i]:\n",
    "            perturbations_made.append((i, f[i]))\n",
    "            \n",
    "    return perturbations_made\n",
    "\n",
    "def get_possible_combinations(perturbations_made):\n",
    "    subsets = []\n",
    "    for r in range(1, len(perturbations_made) + 1):\n",
    "        subsets.extend(itertools.combinations(perturbations_made, r))\n",
    "    result = [list(subset) for subset in subsets]\n",
    "    return result\n",
    "\n",
    "def get_minimum_change_for_perturbation(perturbed_chosen, index_in_list, training=True):\n",
    "    i, s, f = perturbed_chosen[index_in_list]\n",
    "    event_target = events_picked[i]\n",
    "    combination_of_perturbation = get_possible_combinations(get_changes_list(s, f))\n",
    "    for i in range(len(combination_of_perturbation)):\n",
    "        combination = combination_of_perturbation[i]\n",
    "        copy = to_cuda(torch.tensor(s).detach())\n",
    "        for index_of_change, value_of_change in combination:\n",
    "            copy[index_of_change] = value_of_change\n",
    "        copy.resize_(1, copy.size()[-1])\n",
    "        output = builder.predict(to_one_hot(copy), training=training)\n",
    "        indices_of_results, _ = get_results(output)\n",
    "        if event_target != indices_of_results[0]:\n",
    "            return copy, f\"Shortcut: {combination_of_perturbation[-1]} -> {combination}\\n\" if i == len(combination_of_perturbation) - 1 and len(combination_of_perturbation) != 1 else \"\"\n",
    "    # print(f\"ERROR: Could not find a perturbation for {index_in_list} [{i}]\")\n",
    "    # print(f\"       Cannot go from {format_list(s)}\")\n",
    "    # print(f\"                      {format_list(f)}\")\n",
    "    \n",
    "    return None, False\n",
    "\n",
    "def process_single(context_chosen, training=True):\n",
    "    result_string = \"\"\n",
    "    context_chosen = to_cuda(context_chosen)\n",
    "    output = predict_single(context_chosen, training=training)\n",
    "    attentions = [round(x, 5) for x in output[1][0][0].tolist()]\n",
    "    indices_of_results, prediction_str = get_results(output)\n",
    "    result_string += f\"{format_list(context_chosen[0].tolist())} -> {prediction_str}\\n\"\n",
    "    for c, a in zip(context_chosen[0], attentions):\n",
    "        result_string += f\"[{c:2}] {'{:.5f}'.format(a)} \"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "    \n",
    "def predict_single(context_chosen, training=True):\n",
    "    context_chosen.resize_(1, context_chosen.size()[-1])\n",
    "    context_one_hot = to_one_hot(context_chosen)\n",
    "    return builder.predict(context_one_hot, training=training)\n",
    "\n",
    "def predict_single_from_list(list_picked, index_picked):\n",
    "    return predict_single(to_cuda(list_picked[index_picked:index_picked+1].detach()))\n",
    "\n",
    "def analysis(perturbed_chosen, index_picked, training=True):\n",
    "    result_string = \"\"\n",
    "    i, s, f = perturbed_chosen[index_picked]\n",
    "    minimum_change_for_perturbation, final_combination = get_minimum_change_for_perturbation(perturbed_chosen, index_picked, training=training)\n",
    "    if minimum_change_for_perturbation is not None:\n",
    "        result_string += f\"Analyzing [{i}], Perturbations [{count_list_diff(s, f)}], Index [{index_picked}]\\n\"\n",
    "        result_string += process_single(torch.tensor(s), training=training)\n",
    "        result_string += process_single(minimum_change_for_perturbation, training=training)\n",
    "        result_string += final_combination\n",
    "    else:\n",
    "        result_string += f\"Change did not work on [{i}], Index [{index_picked}]\\n\"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "\n",
    "def store(perturbed_chosen, training=True):\n",
    "    with open(f\"results_attention/length={l}, alpha={v_alpha}, epsilon={v_epsilon}, num_iterations={v_num_iterations}.txt\", \"w\") as file:\n",
    "        safe_to_file = \"\"\n",
    "        skipped = 0\n",
    "        shortcuts = 0\n",
    "        for perturbed_element in range(len(perturbed_chosen)):\n",
    "            r_string = analysis(perturbed_chosen, perturbed_element, training=training)\n",
    "            if \"Change did not work on\" in r_string:\n",
    "                skipped += 1\n",
    "            if \"Shortcut\" in r_string:\n",
    "                shortcuts += 1\n",
    "            print(r_string, end=\"\")\n",
    "            safe_to_file += r_string\n",
    "        skipped_str = f\"Results: {skipped=}/{shortcuts=} out of {len(perturbed_chosen)}\"\n",
    "        print(skipped_str)\n",
    "        safe_to_file += skipped_str\n",
    "        file.write(safe_to_file)"
   ],
   "id": "8584f3097d3d5086",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T11:07:49.666234Z",
     "start_time": "2024-10-01T11:07:49.658761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "store(perturbed_collected, training=True)"
   ],
   "id": "c3abed99e82cd186",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: skipped=0/shortcuts=0 out of 0\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T11:07:52.955752Z",
     "start_time": "2024-10-01T11:07:49.667370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def interpret():\n",
    "    for c, e in zip(context_test, events_test):\n",
    "        cont = to_one_hot(c)\n",
    "        cont = to_cuda(cont.unsqueeze(0))\n",
    "        even = to_cuda(e.reshape(-1, 1))\n",
    "        print(interpreter.predict(X=cont, y=even, verbose=True))\n",
    "        \n",
    "interpret()"
   ],
   "id": "21b0310cc8dabc8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing query: 100%|██████████| 100/100 [00:01<00:00, 75.25it/s]\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 251.85it/s]\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 612.99it/s]\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 483.83it/s]\n",
      "Optimizing query:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n",
      "[3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 529.46it/s]\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 786.78it/s]\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 585.66it/s]\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 644.39it/s]\n",
      "Optimizing query:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n",
      "[3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 457.73it/s]\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 460.71it/s]\n",
      "Optimizing query:  26%|██▌       | 26/100 [00:00<00:00, 251.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 321.84it/s]\n",
      "Predicting      : 100%|██████████| 1/1 [00:00<00:00, 976.10it/s]\n",
      "Optimizing query: 100%|██████████| 100/100 [00:00<00:00, 575.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m         even \u001B[38;5;241m=\u001B[39m to_cuda(e\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m      6\u001B[0m         \u001B[38;5;28mprint\u001B[39m(interpreter\u001B[38;5;241m.\u001B[39mpredict(X\u001B[38;5;241m=\u001B[39mcont, y\u001B[38;5;241m=\u001B[39meven, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n\u001B[0;32m----> 8\u001B[0m \u001B[43minterpret\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 6\u001B[0m, in \u001B[0;36minterpret\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m cont \u001B[38;5;241m=\u001B[39m to_cuda(cont\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m))\n\u001B[1;32m      5\u001B[0m even \u001B[38;5;241m=\u001B[39m to_cuda(e\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43minterpreter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcont\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meven\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m~/Documents/Thesis/DeepCASE/deepcase_copy/interpreter/interpreter.py:186\u001B[0m, in \u001B[0;36mInterpreter.predict\u001B[0;34m(self, X, y, iterations, batch_size, verbose)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Predict maliciousness of context samples.\u001B[39;00m\n\u001B[1;32m    148\u001B[0m \n\u001B[1;32m    149\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    176\u001B[0m \u001B[38;5;124;03m        * -3: Closest cluster > epsilon\u001B[39;00m\n\u001B[1;32m    177\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m    178\u001B[0m \u001B[38;5;66;03m# Get unique samples\u001B[39;00m\n\u001B[1;32m    179\u001B[0m \u001B[38;5;66;03m# X, y, inverse_result = unique_2d(X, y)\u001B[39;00m\n\u001B[1;32m    180\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    184\u001B[0m \n\u001B[1;32m    185\u001B[0m \u001B[38;5;66;03m# Compute vectors\u001B[39;00m\n\u001B[0;32m--> 186\u001B[0m vectors, mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattended_context\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    187\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m           \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    188\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[43m           \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[43m   \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mthreshold\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    190\u001B[0m \u001B[43m    \u001B[49m\u001B[43miterations\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43miterations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    191\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    192\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m     \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    193\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    195\u001B[0m \u001B[38;5;66;03m# Initialise result\u001B[39;00m\n\u001B[1;32m    196\u001B[0m result \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mfull(vectors\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m4\u001B[39m, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mfloat\u001B[39m)\n",
      "File \u001B[0;32m~/Documents/Thesis/DeepCASE/deepcase_copy/interpreter/interpreter.py:722\u001B[0m, in \u001B[0;36mInterpreter.attended_context\u001B[0;34m(self, X, y, threshold, iterations, batch_size, verbose)\u001B[0m\n\u001B[1;32m    719\u001B[0m logger\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mattended_context: Create vectors\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    720\u001B[0m \u001B[38;5;66;03m# print(f\"{mask=} {torch.argmax(X[mask], axis=-1).tolist()[0]=}\")\u001B[39;00m\n\u001B[1;32m    721\u001B[0m \u001B[38;5;66;03m# Perform vectorization\u001B[39;00m\n\u001B[0;32m--> 722\u001B[0m X_temp \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmask\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[1;32m    723\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m    724\u001B[0m     X_temp \u001B[38;5;241m=\u001B[39m X_temp\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T11:07:52.957711Z",
     "start_time": "2024-10-01T11:07:52.957332Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "3160d63d803c8ea7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
