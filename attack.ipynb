{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-24T10:17:44.427751Z",
     "start_time": "2024-09-24T10:17:44.366937Z"
    }
   },
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from deepcase_copy.context_builder.context_builder import ContextBuilder\n",
    "from deepcase_copy.interpreter.interpreter import Interpreter\n",
    "\n",
    "def to_cuda(item):\n",
    "    if torch.cuda.is_available():\n",
    "        return item.to('cuda')\n",
    "    return item\n",
    "\n",
    "builder = to_cuda(ContextBuilder.load('save/builder.save'))\n",
    "interpreter = Interpreter.load('save/interpreter.save', builder)\n",
    "\n",
    "with open('save/sequences.save', 'rb') as infile:\n",
    "    data = torch.load(infile)\n",
    "    events  = data[\"events\"]\n",
    "    context = data[\"context\"]\n",
    "    labels  = data[\"labels\"]\n",
    "    mapping = data[\"mapping\"]\n",
    "    \n",
    "    events_train  = to_cuda(events [:events.shape[0]//5 ])\n",
    "    events_test   = to_cuda(events [ events.shape[0]//5:])\n",
    "    \n",
    "    context_train = to_cuda(context[:events.shape[0]//5 ])\n",
    "    context_test  = to_cuda(context[ events.shape[0]//5:])\n",
    "    \n",
    "    labels_train  = to_cuda(labels [:events.shape[0]//5 ])\n",
    "    labels_test   = to_cuda(labels [ events.shape[0]//5:])"
   ],
   "outputs": [],
   "execution_count": 180
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T09:13:56.122940Z",
     "start_time": "2024-09-24T09:13:53.068426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_unique_indices_per_row(tensor):\n",
    "    indices_list = []\n",
    "    row_list = []\n",
    "    indices_list_set = set()\n",
    "    \n",
    "    for row in range(len(tensor)):\n",
    "        curr = tuple(tensor[row].tolist())\n",
    "        \n",
    "        if curr in indices_list_set:\n",
    "            continue\n",
    "        \n",
    "        row_list.append(curr)\n",
    "        indices_list.append(row)\n",
    "        indices_list_set.add(curr)\n",
    "    \n",
    "    return indices_list, row_list\n",
    "indices, rows = get_unique_indices_per_row(context_test)"
   ],
   "id": "fc89a960fc4f0603",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:25:20.544825Z",
     "start_time": "2024-09-24T11:25:20.471022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from deepcase_copy.context_builder.loss import LabelSmoothing\n",
    "\n",
    "MAX_ITER = 100\n",
    "PERTURB_THRESHOLD = 3\n",
    "\n",
    "def to_one_hot(t):\n",
    "    return builder.embedding_one_hot(t)\n",
    "\n",
    "def max_to_one(tensor):\n",
    "    max_indices = torch.argmax(tensor, dim=-1, keepdim=True)\n",
    "    result = torch.zeros_like(tensor)\n",
    "    result.scatter_(-1, max_indices, 1.0)\n",
    "    return result\n",
    "\n",
    "def get_results(results):\n",
    "    results_picked = torch.topk(results[0][0][0], 3)\n",
    "    exp = results_picked.values.exp()\n",
    "    res_indices = results_picked.indices\n",
    "    s = []\n",
    "    for j in range(3):\n",
    "        s.append(f\"{format_list([res_indices[j].item()])} {'{:.3f}'.format(exp[j])}\")\n",
    "    return res_indices, \", \".join(s)\n",
    "\n",
    "def compute_change(trace, original, epsilon=0.1):\n",
    "    a = original - epsilon\n",
    "    b = (trace >= a).float() * trace + (trace < a).float() * a\n",
    "    c = (b > original + epsilon).float() * (original + epsilon) + (b <= original + epsilon).float() * b\n",
    "    return max_to_one(c), c\n",
    "\n",
    "def bim_attack(context_given, target_given, alpha=0.1, epsilon=0.1, num_iterations=MAX_ITER):\n",
    "    change = None\n",
    "    original_context = to_one_hot(context_given)\n",
    "    context_processed = to_one_hot(context_given)\n",
    "    criterion = LabelSmoothing(builder.decoder_event.out.out_features, 0.1)    \n",
    "    changes = []\n",
    "    computed_change_collected = []\n",
    "    for i in range(num_iterations):\n",
    "        context_processed.requires_grad_(True)\n",
    "        output = builder.predict(context_processed)\n",
    "        indices_of_results, prediction_str = get_results(output)\n",
    "        changes.append({\n",
    "            \"changed_to\": torch.argmax(context_processed, axis=-1).tolist()[0],\n",
    "            \"prediction_str\": prediction_str,\n",
    "        })\n",
    "        if target_given[0] != indices_of_results[0]:\n",
    "            break\n",
    "        loss = criterion(output[0][0], target_given)\n",
    "        context_processed.retain_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        grad = context_processed.grad.sign()\n",
    "        if change is None:\n",
    "            change = alpha * grad\n",
    "        else:\n",
    "            change += alpha * grad\n",
    "        context_processed = context_processed + change\n",
    "        context_processed, computed_change = compute_change(context_processed, original_context, epsilon)\n",
    "        computed_change_collected.append(computed_change)\n",
    "    return changes, computed_change_collected\n",
    "\n",
    "def count_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    return count_list_diff(orig, final)\n",
    "\n",
    "def count_list_diff(orig, final):\n",
    "    changed_entries = 0\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig != final:\n",
    "            changed_entries += 1\n",
    "    return changed_entries\n",
    "    \n",
    "def show_changes(changes_needed):\n",
    "    orig = changes_needed[0][\"changed_to\"]\n",
    "    final = changes_needed[-1][\"changed_to\"]\n",
    "    changes = []\n",
    "    same = []\n",
    "    for orig, final in zip(orig, final):\n",
    "        if orig == final:\n",
    "            changes.append(\"-\")\n",
    "            same.append(final)\n",
    "        else:\n",
    "            changes.append(final)\n",
    "            same.append(\"XX\")\n",
    "    return format_list(changes), format_list(same)\n",
    "\n",
    "def format_list(li):\n",
    "    return f\"[{\", \".join([f'{num:2}' for num in li])}]\"\n",
    "            \n",
    "def format_line(current_trace_num, changes_needed, i):\n",
    "    start = \" \"*(len(str(current_trace_num)) + 2)\n",
    "    if i != 0:\n",
    "        if len(str(current_trace_num)) == 1:\n",
    "            start = f'{i:<3}'\n",
    "        elif len(str(current_trace_num)) == 2:\n",
    "            start = f'{i:<4}'\n",
    "        elif len(str(current_trace_num)) == 3:\n",
    "            start = f'{i:<5}'\n",
    "        elif len(str(current_trace_num)) == 4:\n",
    "            start = f'{i:<6}'\n",
    "        else:\n",
    "            start = f'{i:<7}'\n",
    "        b = list(start)\n",
    "        b[len(str(i))] = '<'\n",
    "        start = ''.join(b)\n",
    "    return f\"{start}{format_list(changes_needed[i][\"changed_to\"])} -> {changes_needed[i]['prediction_str']}\\n\"\n",
    "            \n",
    "def print_state(changes_needed, current_trace_num, con, event_chosen, change_collected, print_path=True, include_change=True, num_iterations=MAX_ITER):\n",
    "    mode_int = 0\n",
    "    changed_num = len(changes_needed)\n",
    "    perturbations_num = count_changes(changes_needed)\n",
    "    result_string = \"\"\n",
    "    if changed_num == 1:\n",
    "        pass\n",
    "    elif changed_num == num_iterations:\n",
    "        mode_int = 3\n",
    "    else:\n",
    "        mode_int = 1\n",
    "        if perturbations_num <= PERTURB_THRESHOLD:\n",
    "            mode_int = 2\n",
    "            result_string += f\"{current_trace_num}: {format_list(con[0].tolist())} == {event_chosen.tolist()} Changed {{{changed_num}}}, Perturbations {{{perturbations_num}}}\\n\"\n",
    "            if print_path:\n",
    "                for i in range(len(changes_needed)):\n",
    "                    result_string += format_line(current_trace_num, changes_needed, i)                    \n",
    "                    if include_change:\n",
    "                        if i is not len(changes_needed) - 1:\n",
    "                            result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)} {change_collected[i]=}\\n\"\n",
    "            else:\n",
    "                for i in range(len(changes_needed)):\n",
    "                    if i == 0 or (changes_needed[i][\"changed_to\"] != changes_needed[i-1][\"changed_to\"] and i != len(changes_needed) - 1):\n",
    "                        result_string += format_line(current_trace_num, changes_needed, i)\n",
    "                change_last = changes_needed[-1]\n",
    "                result_string += f\"{\" \"*(len(str(current_trace_num)) + 2)}{format_list(change_last[\"changed_to\"])} -> {change_last['prediction_str']}\\n\"\n",
    "            changed_entries, same_entries = show_changes(changes_needed)\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}== {same_entries}\\n\"\n",
    "            result_string += f\"{\" \"*(len(str(current_trace_num)) - 1)}-> {changed_entries}\\n\"\n",
    "            result_string += \"\\n\" \n",
    "    return mode_int, result_string\n",
    "\n",
    "def process_traces(context_to_process, events_to_process, alpha=0.01, epsilon=0.5, num_iterations=100, print_path=False, include_change=False, write_to_file=False, print_result=False):\n",
    "    perturbed_collected_main = []\n",
    "    states = [0, 0, 0, 0]\n",
    "    safe_to_file = \"\"\n",
    "    iters = range(len(context_to_process))\n",
    "    if not print_result:\n",
    "        iters = tqdm(iters)\n",
    "    for current_trace_num in iters:\n",
    "        con, e = context_to_process[current_trace_num], events_to_process.unsqueeze(1)[current_trace_num]\n",
    "        con.resize_(1, con.size()[-1])\n",
    "        changes_needed, change_collected = bim_attack(context_given=con, target_given=e, alpha=alpha, epsilon=epsilon, num_iterations=num_iterations)\n",
    "        mode_int, result_string = print_state(changes_needed, current_trace_num, con, e, change_collected, print_path=print_path, include_change=include_change, num_iterations=num_iterations)\n",
    "        if print_result:\n",
    "            print(result_string, end=\"\")\n",
    "        safe_to_file += result_string\n",
    "        if mode_int == 2:\n",
    "            perturbed_collected_main.append((current_trace_num, changes_needed[0]['changed_to'], changes_needed[-1]['changed_to']))\n",
    "        states[mode_int] += 1\n",
    "    print(f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\")\n",
    "    safe_to_file += f\"incorrect={states[0]} changed={states[1]} perturbed={states[2]} timeout={states[3]}\"\n",
    "    if write_to_file:\n",
    "        with open(f\"results_trace/length={l}, alpha={alpha}, epsilon={epsilon}, num_iterations={num_iterations}, print_path={print_path} include_change={include_change}.txt\", \"w\") as f:\n",
    "            f.write(safe_to_file)\n",
    "    return perturbed_collected_main"
   ],
   "id": "aed0a48282625435",
   "outputs": [],
   "execution_count": 231
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:26:21.588172Z",
     "start_time": "2024-09-24T11:26:21.525043Z"
    }
   },
   "cell_type": "code",
   "source": [
    "l = 1\n",
    "chosen_index = 3\n",
    "context_picked = to_cuda(context_test[indices][chosen_index:chosen_index+l].clone().detach())\n",
    "events_picked = to_cuda(events_test[indices][chosen_index:chosen_index+l].clone().detach())\n",
    "labels_picked = to_cuda(labels_test[indices][chosen_index:chosen_index+l].clone().detach())"
   ],
   "id": "5b0deb007a15fad7",
   "outputs": [],
   "execution_count": 247
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:26:21.894033Z",
     "start_time": "2024-09-24T11:26:21.885535Z"
    }
   },
   "cell_type": "code",
   "source": [
    "v_alpha=0.01\n",
    "v_epsilon=0.5\n",
    "v_num_iterations=100\n",
    "v_print_path=False\n",
    "v_include_change=True\n",
    "v_print_result=True\n",
    "v_write_to_file=False"
   ],
   "id": "65df71a7a8cdba78",
   "outputs": [],
   "execution_count": 248
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-24T11:26:22.645550Z",
     "start_time": "2024-09-24T11:26:22.302335Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "perturbed_collected = process_traces(context_picked, events_picked, alpha=v_alpha, epsilon=v_epsilon, num_iterations=v_num_iterations, print_path=v_print_path, include_change=v_include_change, write_to_file=v_write_to_file, print_result=v_print_result)    "
   ],
   "id": "cae0ecf8074ff9d3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: [86, 87, 86, 87, 66, 66, 42, 42, 42, 72] == [72] Changed {52}, Perturbations {2}\n",
      "   [86, 87, 86, 87, 66, 66, 42, 42, 42, 72] -> [72] 0.509, [42] 0.218, [78] 0.023\n",
      "   [86, 87, 86, 87, 66, 66,  1, 42, 42,  1] -> [ 1] 0.234, [15] 0.118, [72] 0.027\n",
      "== [86, 87, 86, 87, 66, 66, XX, 42, 42, XX]\n",
      "-> [- , - , - , - , - , - ,  1, - , - ,  1]\n",
      "\n",
      "incorrect=0 changed=0 perturbed=1 timeout=0\n"
     ]
    }
   ],
   "execution_count": 249
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "def weird_case():\n",
    "    _, _, final_item = perturbed_collected[5]\n",
    "    final_item = to_cuda(torch.tensor(final_item).detach())\n",
    "    final_item.resize_(1, final_item.size()[-1])\n",
    "    output = builder.predict(to_one_hot(final_item))\n",
    "    indices_of_results, print_results = get_results(output)\n",
    "    print(print_results)\n",
    "\n",
    "weird_case()"
   ],
   "id": "96ae1655d1c0c74f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import itertools\n",
    "\n",
    "def get_changes_list(s, f):\n",
    "    perturbations_made = []\n",
    "    for i in range(len(s)):\n",
    "        if s[i] != f[i]:\n",
    "            perturbations_made.append((i, f[i]))\n",
    "            \n",
    "    return perturbations_made\n",
    "\n",
    "def get_possible_combinations(perturbations_made):\n",
    "    subsets = []\n",
    "    for r in range(1, len(perturbations_made) + 1):\n",
    "        subsets.extend(itertools.combinations(perturbations_made, r))\n",
    "    result = [list(subset) for subset in subsets]\n",
    "    return result\n",
    "\n",
    "def get_minimum_change_for_perturbation(perturbed_chosen, index_in_list):\n",
    "    i, s, f = perturbed_chosen[index_in_list]\n",
    "    event_target = events_picked[i]\n",
    "    combination_of_perturbation = get_possible_combinations(get_changes_list(s, f))\n",
    "    for combination in combination_of_perturbation:\n",
    "        copy = to_cuda(torch.tensor(s).detach())\n",
    "        for index_of_change, value_of_change in combination:\n",
    "            copy[index_of_change] = value_of_change\n",
    "        copy.resize_(1, copy.size()[-1])\n",
    "        output = builder.predict(to_one_hot(copy))\n",
    "        indices_of_results, _ = get_results(output)\n",
    "        if event_target != indices_of_results[0]:\n",
    "            return copy\n",
    "    # print(f\"ERROR: Could not find a perturbation for {index_in_list} [{i}]\")\n",
    "    # print(f\"       Cannot go from {format_list(s)}\")\n",
    "    # print(f\"                      {format_list(f)}\")\n",
    "    \n",
    "    return None\n",
    "\n",
    "def process_single(context_chosen):\n",
    "    result_string = \"\"\n",
    "    context_chosen = to_cuda(context_chosen)\n",
    "    output = predict_single(context_chosen)\n",
    "    attentions = [round(x, 5) for x in output[1][0][0].tolist()]\n",
    "    indices_of_results, prediction_str = get_results(output)\n",
    "    result_string += f\"{format_list(context_chosen[0].tolist())} -> {prediction_str}\\n\"\n",
    "    for c, a in zip(context_chosen[0], attentions):\n",
    "        result_string += f\"[{c:2}] {'{:.5f}'.format(a)} \"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "\n",
    "def predict_single(context_chosen):\n",
    "    context_chosen.resize_(1, context_chosen.size()[-1])\n",
    "    context_one_hot = to_one_hot(context_chosen)\n",
    "    return builder.predict(context_one_hot)\n",
    "\n",
    "def predict_single_from_list(list_picked, index_picked):\n",
    "    return predict_single(to_cuda(list_picked[index_picked:index_picked+1].detach()))\n",
    "\n",
    "def analysis(perturbed_chosen, index_picked):\n",
    "    result_string = \"\"\n",
    "    i, s, f = perturbed_chosen[index_picked]\n",
    "    minimum_change_for_perturbation = get_minimum_change_for_perturbation(perturbed_chosen, index_picked)\n",
    "    if minimum_change_for_perturbation is not None:\n",
    "        result_string += f\"Analyzing [{i}], Perturbations [{count_list_diff(s, f)}], Index [{index_picked}]\\n\"\n",
    "        result_string += process_single(torch.tensor(s))\n",
    "        result_string += process_single(minimum_change_for_perturbation)\n",
    "    else:\n",
    "        result_string += f\"Change did not work on [{i}], Index [{index_picked}]\"\n",
    "    result_string += \"\\n\"\n",
    "    return result_string\n",
    "\n",
    "def store(perturbed_chosen):\n",
    "    with open(f\"results_attention/length={l}, alpha={v_alpha}, epsilon={v_epsilon}, num_iterations={v_num_iterations}.txt\", \"w\") as file:\n",
    "        safe_to_file = \"\"\n",
    "        skipped = 0\n",
    "        for perturbed_element in range(len(perturbed_chosen)):\n",
    "            r_string = analysis(perturbed_chosen, perturbed_element)\n",
    "            if \"Change did not work on\" in r_string:\n",
    "                skipped += 1\n",
    "            print(r_string, end=\"\")\n",
    "            safe_to_file += r_string\n",
    "        skipped_str = f\"Had to skip {skipped} out of {len(perturbed_chosen)}\"\n",
    "        print(skipped_str)\n",
    "        safe_to_file += skipped_str\n",
    "        file.write(safe_to_file)"
   ],
   "id": "8584f3097d3d5086",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "predict_single_from_list(context_test, 1)"
   ],
   "id": "450ce74994acb228",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.manual_seed(42)\n",
    "store(perturbed_collected)"
   ],
   "id": "c3abed99e82cd186",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def interpret():\n",
    "    for c, e in zip(context_test, events_test):\n",
    "        cont = to_one_hot(c)\n",
    "        cont = to_cuda(cont.unsqueeze(0))\n",
    "        even = to_cuda(e.reshape(-1, 1))\n",
    "        print(interpreter.predict(X=cont, y=even, verbose=True))\n",
    "        \n",
    "interpret()"
   ],
   "id": "21b0310cc8dabc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3160d63d803c8ea7",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
